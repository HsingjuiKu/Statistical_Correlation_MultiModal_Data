{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils import load_data, flatten_data\n",
    "from early_model import stacked_lstm\n",
    "from model_utils import model_pipeline, plot_history\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import spearmanr\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.layers import BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C56D is not selected to be used for training (downsampling)\n",
      "C93D is not selected to be used for training (downsampling)\n",
      "C382D is not selected to be used for training (downsampling)\n",
      "C382N is not selected to be used for training (downsampling)\n",
      "C544D is not selected to be used for training (downsampling)\n",
      "C709N is not selected to be used for training (downsampling)\n",
      "C788N is not selected to be used for training (downsampling)\n",
      "P113D is selected to be used for training (downsampling)\n",
      "P113N is selected to be used for training (downsampling)\n",
      "P191D is selected to be used for training (downsampling)\n",
      "P191N is selected to be used for training (downsampling)\n",
      "P299D is selected to be used for training (downsampling)\n",
      "P299N is selected to be used for training (downsampling)\n",
      "P300D is selected to be used for training (downsampling)\n",
      "P336D is selected to be used for training (downsampling)\n",
      "P492D is selected to be used for training (downsampling)\n",
      "P492N is selected to be used for training (downsampling)\n",
      "P531N is selected to be used for training (downsampling)\n",
      "P699D is selected to be used for training (downsampling)\n",
      "P699N is selected to be used for training (downsampling)\n",
      "P890N is selected to be used for training (downsampling)\n",
      "P921D is selected to be used for training (downsampling)\n",
      "P921N is selected to be used for training (downsampling)\n"
     ]
    }
   ],
   "source": [
    "train_participant_num = [\"C56D\", \"C93D\", \"C382D\", \"C382N\", \"C544D\", \"C709N\", \"C788N\", \"P113D\", \"P113N\", \"P191D\", \"P191N\", \"P299D\", \"P299N\", \"P300D\", \"P336D\", \"P492D\", \"P492N\", \"P531N\", \"P699D\", \"P699N\", \"P890N\", \"P921D\", \"P921N\"]\n",
    "valid_participant_num = [\"C67D\", \"C202D\", \"C202N\", \"C256D\", \"C256N\", \"P54D\", \"P54N\", \"P342D\", \"P342N\", \"P487D\", \"P487N\", \"P649N\"]\n",
    "\n",
    "X_train, y_train = load_data(train_participant_num, 'train', downsampling=True, angle_energy=False, augment=False)\n",
    "X_valid, y_valid = load_data(valid_participant_num, 'validation')\n",
    "\n",
    "num_classes = y_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#X,Y,Z Coordinates\n",
    "X_train_pose = X_train[:, :, 0:66]\n",
    "X_valid_pose = X_valid[:, :, 0:66]\n",
    "#sEMG\n",
    "X_train_sEMG = X_train[:, :, 66:70]\n",
    "X_valid_sEMG = X_valid[:, :, 66:70]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1111111111111111\n",
      "0.1111111111111111\n",
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "xyz_correlations = []\n",
    "for i in range(66):  # 遍历每个特征\n",
    "    repeated_y_train = np.repeat(y_train, X_train_pose.shape[1], axis=0)\n",
    "    coef, _ = spearmanr(X_train_pose[:, :, i].flatten(), repeated_y_train[:X_train_pose[:, :, i].flatten().shape[0]])\n",
    "    xyz_correlations.append(coef)\n",
    "\n",
    "avg_xyz_correlation = np.mean(xyz_correlations)\n",
    "\n",
    "sEMG_correlations = []\n",
    "for i in range(4):  # sEMG数据有4个通道\n",
    "    repeated_y_train_sEMG = np.repeat(y_train, X_train_sEMG.shape[1], axis=0)\n",
    "    coef, _ = spearmanr(X_train_sEMG[:, :, i].flatten(), repeated_y_train_sEMG[:X_train_sEMG[:, :, i].flatten().shape[0]])\n",
    "    sEMG_correlations.append(coef)\n",
    "\n",
    "avg_sEMG_correlation = np.mean(sEMG_correlations)\n",
    "\n",
    "print(avg_xyz_correlation)\n",
    "print(avg_sEMG_correlation)\n",
    "\n",
    "all_correlations = []\n",
    "all_correlations.append(avg_xyz_correlation)\n",
    "all_correlations.append(avg_sEMG_correlation)\n",
    "\n",
    "abs_correlations = np.abs(all_correlations)\n",
    "normalized_weights = abs_correlations / np.sum(abs_correlations)\n",
    "print(normalized_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def cnn_normal(input_shape):\n",
    "    \"\"\"\n",
    "    Creates a simple 1D CNN model for processing time series data with a dynamic input shape.\n",
    "\n",
    "    Args:\n",
    "    input_shape (tuple): The shape of the input data, excluding the batch size.\n",
    "\n",
    "    Returns:\n",
    "    keras.engine.training.Model: A 1D CNN model.\n",
    "    \"\"\"\n",
    "    input_data = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layer block 1\n",
    "    x = Conv1D(32, 3, padding='same')(input_data)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # Convolutional layer block 2\n",
    "    x = Conv1D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # Convolutional layer block 3\n",
    "    x = Conv1D(128, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "\n",
    "    # Flattening the output and adding Dense layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(2, activation='softmax')(x)  # Assuming a binary classification task\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=out)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.4435 - binary_accuracy: 0.6931 - val_loss: 0.7295 - val_binary_accuracy: 0.2740 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.3261 - binary_accuracy: 0.6588 - val_loss: 0.1508 - val_binary_accuracy: 0.6473 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.1808 - binary_accuracy: 0.6921 - val_loss: 0.1885 - val_binary_accuracy: 0.4054 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.1273 - binary_accuracy: 0.7995 - val_loss: 0.3293 - val_binary_accuracy: 0.0913 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 0.1081 - binary_accuracy: 0.8232 - val_loss: 0.2155 - val_binary_accuracy: 0.2499 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.0937 - binary_accuracy: 0.8454 - val_loss: 0.2072 - val_binary_accuracy: 0.3071 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0865 - binary_accuracy: 0.8490 - val_loss: 0.1849 - val_binary_accuracy: 0.3712 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0796 - binary_accuracy: 0.8623 - val_loss: 0.1620 - val_binary_accuracy: 0.6623 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0779 - binary_accuracy: 0.8615 - val_loss: 0.1140 - val_binary_accuracy: 0.9101 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0691 - binary_accuracy: 0.8855 - val_loss: 0.1150 - val_binary_accuracy: 0.8571 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0627 - binary_accuracy: 0.8927 - val_loss: 0.0927 - val_binary_accuracy: 0.9035 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0636 - binary_accuracy: 0.8955 - val_loss: 0.0806 - val_binary_accuracy: 0.9376 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.0595 - binary_accuracy: 0.8974 - val_loss: 0.0808 - val_binary_accuracy: 0.9362 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.0548 - binary_accuracy: 0.9184 - val_loss: 0.0740 - val_binary_accuracy: 0.9373 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.0561 - binary_accuracy: 0.9090 - val_loss: 0.0687 - val_binary_accuracy: 0.9404 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0562 - binary_accuracy: 0.8998 - val_loss: 0.0702 - val_binary_accuracy: 0.9345 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.0648 - binary_accuracy: 0.9018 - val_loss: 0.0611 - val_binary_accuracy: 0.9268 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.0530 - binary_accuracy: 0.9164 - val_loss: 0.0742 - val_binary_accuracy: 0.9313 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0535 - binary_accuracy: 0.9116 - val_loss: 0.0790 - val_binary_accuracy: 0.9150 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0515 - binary_accuracy: 0.9112 - val_loss: 0.0755 - val_binary_accuracy: 0.9247 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.0494 - binary_accuracy: 0.9146 - val_loss: 0.0773 - val_binary_accuracy: 0.9125 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.0479 - binary_accuracy: 0.9220 - val_loss: 0.0691 - val_binary_accuracy: 0.9400 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0504 - binary_accuracy: 0.9188 - val_loss: 0.0850 - val_binary_accuracy: 0.8944 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0484 - binary_accuracy: 0.9140 - val_loss: 0.0730 - val_binary_accuracy: 0.9226 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 0.0464 - binary_accuracy: 0.9208 - val_loss: 0.0867 - val_binary_accuracy: 0.8627 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 0.0434 - binary_accuracy: 0.9326 - val_loss: 0.0842 - val_binary_accuracy: 0.8895 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0413 - binary_accuracy: 0.9326 - val_loss: 0.0932 - val_binary_accuracy: 0.8721 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0380 - binary_accuracy: 0.9467 - val_loss: 0.0886 - val_binary_accuracy: 0.8770 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.0367 - binary_accuracy: 0.9449 - val_loss: 0.0982 - val_binary_accuracy: 0.8752 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.0352 - binary_accuracy: 0.9485 - val_loss: 0.0976 - val_binary_accuracy: 0.8585 - lr: 3.5849e-04\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      2698\n",
      "           1       0.16      0.32      0.21       171\n",
      "\n",
      "    accuracy                           0.86      2869\n",
      "   macro avg       0.56      0.60      0.57      2869\n",
      "weighted avg       0.91      0.86      0.88      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2409  289]\n",
      " [ 117   54]]\n"
     ]
    }
   ],
   "source": [
    "#分割成两个模态\n",
    "model_pose = cnn_normal(input_shape=(180, 66))\n",
    "y_pred_pose, y_true_pose, H_pose = model_pipeline(model_pose, X_train_pose, y_train, X_valid_pose, y_valid, epoch=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 0.5327 - binary_accuracy: 0.7143 - val_loss: 0.1714 - val_binary_accuracy: 0.8613 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.1399 - binary_accuracy: 0.7518 - val_loss: 0.1466 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.1174 - binary_accuracy: 0.7937 - val_loss: 0.1301 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1122 - binary_accuracy: 0.8031 - val_loss: 0.1269 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.1136 - binary_accuracy: 0.8057 - val_loss: 0.1150 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.1086 - binary_accuracy: 0.8198 - val_loss: 0.1047 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1086 - binary_accuracy: 0.8160 - val_loss: 0.0974 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1046 - binary_accuracy: 0.8216 - val_loss: 0.0924 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1043 - binary_accuracy: 0.8238 - val_loss: 0.0869 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.1009 - binary_accuracy: 0.8328 - val_loss: 0.0832 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.0996 - binary_accuracy: 0.8336 - val_loss: 0.0796 - val_binary_accuracy: 0.9400 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0974 - binary_accuracy: 0.8372 - val_loss: 0.0757 - val_binary_accuracy: 0.9404 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.0945 - binary_accuracy: 0.8414 - val_loss: 0.0720 - val_binary_accuracy: 0.9411 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0945 - binary_accuracy: 0.8404 - val_loss: 0.0702 - val_binary_accuracy: 0.9432 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0926 - binary_accuracy: 0.8436 - val_loss: 0.0658 - val_binary_accuracy: 0.9418 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0894 - binary_accuracy: 0.8480 - val_loss: 0.0617 - val_binary_accuracy: 0.9425 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0885 - binary_accuracy: 0.8569 - val_loss: 0.0596 - val_binary_accuracy: 0.9432 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0860 - binary_accuracy: 0.8551 - val_loss: 0.0567 - val_binary_accuracy: 0.9421 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0838 - binary_accuracy: 0.8633 - val_loss: 0.0554 - val_binary_accuracy: 0.9425 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0829 - binary_accuracy: 0.8667 - val_loss: 0.0558 - val_binary_accuracy: 0.9432 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0827 - binary_accuracy: 0.8677 - val_loss: 0.0495 - val_binary_accuracy: 0.9414 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0789 - binary_accuracy: 0.8677 - val_loss: 0.0520 - val_binary_accuracy: 0.9404 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0772 - binary_accuracy: 0.8749 - val_loss: 0.0518 - val_binary_accuracy: 0.9411 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0759 - binary_accuracy: 0.8757 - val_loss: 0.0450 - val_binary_accuracy: 0.9421 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0730 - binary_accuracy: 0.8825 - val_loss: 0.0453 - val_binary_accuracy: 0.9397 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0715 - binary_accuracy: 0.8841 - val_loss: 0.0435 - val_binary_accuracy: 0.9404 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0713 - binary_accuracy: 0.8855 - val_loss: 0.0412 - val_binary_accuracy: 0.9414 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0682 - binary_accuracy: 0.8873 - val_loss: 0.0414 - val_binary_accuracy: 0.9400 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0667 - binary_accuracy: 0.8949 - val_loss: 0.0421 - val_binary_accuracy: 0.9390 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0654 - binary_accuracy: 0.8980 - val_loss: 0.0412 - val_binary_accuracy: 0.9390 - lr: 3.5849e-04\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      2698\n",
      "           1       0.48      0.23      0.31       171\n",
      "\n",
      "    accuracy                           0.94      2869\n",
      "   macro avg       0.71      0.61      0.64      2869\n",
      "weighted avg       0.92      0.94      0.93      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2655   43]\n",
      " [ 132   39]]\n"
     ]
    }
   ],
   "source": [
    "model_sEMG = cnn_normal(input_shape=(180, 4))\n",
    "y_pred_sEMG, y_true_sEMG, H_sEMG = model_pipeline(model_sEMG, X_train_sEMG, y_train, X_valid_sEMG, y_valid, epoch=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      2698\n",
      "           1       0.43      0.07      0.12       171\n",
      "\n",
      "    accuracy                           0.94      2869\n",
      "   macro avg       0.69      0.53      0.54      2869\n",
      "weighted avg       0.91      0.94      0.92      2869\n",
      "\n",
      "[[2682   16]\n",
      " [ 159   12]]\n"
     ]
    }
   ],
   "source": [
    "weight_pose = normalized_weights[0]\n",
    "weight_sEMG = normalized_weights[1]\n",
    "\n",
    "\n",
    "final_pred = (y_pred_pose * weight_pose + y_pred_sEMG * weight_sEMG) / (weight_pose + weight_sEMG)\n",
    "final_pred = np.round(final_pred).astype(int)\n",
    "\n",
    "\n",
    "print(classification_report(y_true_pose, final_pred))\n",
    "print(confusion_matrix(y_true_pose, final_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      2698\n",
      "           1       0.43      0.07      0.12       171\n",
      "\n",
      "    accuracy                           0.94      2869\n",
      "   macro avg       0.69      0.53      0.54      2869\n",
      "weighted avg       0.91      0.94      0.92      2869\n",
      "\n",
      "[[2682   16]\n",
      " [ 159   12]]\n"
     ]
    }
   ],
   "source": [
    "weight_pose = normalized_weights[0]\n",
    "weight_sEMG = normalized_weights[1]\n",
    "\n",
    "\n",
    "final_pred = (y_pred_pose + y_pred_sEMG) / 2\n",
    "final_pred = np.round(final_pred).astype(int)\n",
    "\n",
    "\n",
    "print(classification_report(y_true_pose, final_pred))\n",
    "print(confusion_matrix(y_true_pose, final_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.6500 - binary_accuracy: 0.7021 - val_loss: 0.0741 - val_binary_accuracy: 0.9387 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.1617 - binary_accuracy: 0.6552 - val_loss: 0.1402 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.1406 - binary_accuracy: 0.7899 - val_loss: 0.1324 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.1289 - binary_accuracy: 0.7899 - val_loss: 0.1511 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.1180 - binary_accuracy: 0.7899 - val_loss: 0.1408 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.1110 - binary_accuracy: 0.7897 - val_loss: 0.1306 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.1038 - binary_accuracy: 0.7897 - val_loss: 0.1213 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.0986 - binary_accuracy: 0.7899 - val_loss: 0.1217 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.0934 - binary_accuracy: 0.7897 - val_loss: 0.1210 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.0910 - binary_accuracy: 0.7899 - val_loss: 0.1103 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 0.0863 - binary_accuracy: 0.7899 - val_loss: 0.1002 - val_binary_accuracy: 0.9404 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.0945 - binary_accuracy: 0.7897 - val_loss: 0.1080 - val_binary_accuracy: 0.9404 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.0837 - binary_accuracy: 0.8200 - val_loss: 0.0743 - val_binary_accuracy: 0.9278 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.0788 - binary_accuracy: 0.8557 - val_loss: 0.0782 - val_binary_accuracy: 0.9212 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.0738 - binary_accuracy: 0.8567 - val_loss: 0.0709 - val_binary_accuracy: 0.9282 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.0725 - binary_accuracy: 0.8667 - val_loss: 0.0799 - val_binary_accuracy: 0.9289 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.0688 - binary_accuracy: 0.8893 - val_loss: 0.0780 - val_binary_accuracy: 0.9324 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.0668 - binary_accuracy: 0.8837 - val_loss: 0.0700 - val_binary_accuracy: 0.9299 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.0662 - binary_accuracy: 0.8921 - val_loss: 0.0899 - val_binary_accuracy: 0.9153 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.0666 - binary_accuracy: 0.8978 - val_loss: 0.0663 - val_binary_accuracy: 0.9355 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.0696 - binary_accuracy: 0.8907 - val_loss: 0.0654 - val_binary_accuracy: 0.9376 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.0747 - binary_accuracy: 0.8877 - val_loss: 0.0937 - val_binary_accuracy: 0.8986 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.0710 - binary_accuracy: 0.8951 - val_loss: 0.0717 - val_binary_accuracy: 0.9418 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.0646 - binary_accuracy: 0.8980 - val_loss: 0.0987 - val_binary_accuracy: 0.9003 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.0629 - binary_accuracy: 0.9046 - val_loss: 0.0707 - val_binary_accuracy: 0.9446 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.0608 - binary_accuracy: 0.9136 - val_loss: 0.0801 - val_binary_accuracy: 0.9278 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.0592 - binary_accuracy: 0.9168 - val_loss: 0.0745 - val_binary_accuracy: 0.9275 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.0574 - binary_accuracy: 0.9178 - val_loss: 0.0947 - val_binary_accuracy: 0.8947 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 0.0561 - binary_accuracy: 0.9274 - val_loss: 0.0781 - val_binary_accuracy: 0.9383 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 0.0551 - binary_accuracy: 0.9260 - val_loss: 0.0885 - val_binary_accuracy: 0.9237 - lr: 3.5849e-04\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      2698\n",
      "           1       0.37      0.38      0.37       171\n",
      "\n",
      "    accuracy                           0.92      2869\n",
      "   macro avg       0.66      0.67      0.67      2869\n",
      "weighted avg       0.93      0.92      0.92      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2585  113]\n",
      " [ 106   65]]\n"
     ]
    }
   ],
   "source": [
    "#打包一起训练\n",
    "model = cnn_normal(input_shape=(180, 70))\n",
    "y_pred, y_true, H = model_pipeline(model, X_train, y_train, X_valid, y_valid, epoch=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations for Trunk: [-0.0005935154175248134]\n",
      "Correlations for Upper Limb: [-5.168494671029889e-05]\n",
      "Correlations for Lower Limb: [-0.000717485724721992]\n",
      "Correlations for sEMG signals: -0.0029697894500262632\n",
      "Correlations for All: [-0.0005935154175248134, -5.168494671029889e-05, -0.000717485724721992, -0.0029697894500262632]\n"
     ]
    }
   ],
   "source": [
    "#分割成四个模态\n",
    "X_train_XYZ = X_train[:, :, :66]  # XYZ坐标\n",
    "X_train_sEMG = X_train[:, :, 66:70]  # sEMG数据\n",
    "\n",
    "# 定义模态分组\n",
    "trunk_indices = [0, 7, 8, 19, 20, 21]  # 身体躯干模态索引\n",
    "upper_limb_indices = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]  # 上肢模态索引\n",
    "lower_limb_indices = [1, 2, 3, 4, 5, 6]  # 下肢模态索引\n",
    "\n",
    "# 初始化相关性列表\n",
    "correlations_trunk = []\n",
    "correlations_upper_limb = []\n",
    "correlations_lower_limb = []\n",
    "\n",
    "# 分别计算每个模态组的相关性\n",
    "for group, correlations in [(trunk_indices, correlations_trunk),\n",
    "                            (upper_limb_indices, correlations_upper_limb),\n",
    "                            (lower_limb_indices, correlations_lower_limb)]:\n",
    "    group_correlations = []\n",
    "    for i in group:\n",
    "        # 获取每个XYZ坐标的展平后的数组\n",
    "        X_flat = X_train[:, :, i].flatten()\n",
    "        Y_flat = X_train[:, :, i+22].flatten()\n",
    "        Z_flat = X_train[:, :, i+44].flatten()\n",
    "        # 为了匹配X_flat, Y_flat, Z_flat的长度，我们需要正确地重复y_train\n",
    "        y_repeated = np.repeat(y_train, X_train.shape[1])\n",
    "        # 计算相关性\n",
    "        coef_X, _ = spearmanr(X_flat, y_repeated[:len(X_flat)])\n",
    "        coef_Y, _ = spearmanr(Y_flat, y_repeated[:len(Y_flat)])\n",
    "        coef_Z, _ = spearmanr(Z_flat, y_repeated[:len(Z_flat)])\n",
    "        # 计算平均相关系数\n",
    "        avg_coef = np.mean([coef_X, coef_Y, coef_Z])\n",
    "        group_correlations.append(avg_coef)\n",
    "    # 计算并保存该模态组的平均相关性\n",
    "    avg_group_correlation = np.mean(group_correlations)\n",
    "    correlations.append(avg_group_correlation)\n",
    "\n",
    "# 对sEMG数据计算相关性\n",
    "correlations_sEMG = []\n",
    "for i in range(4):\n",
    "    sEMG_flat = X_train_sEMG[:, :, i].flatten()\n",
    "    y_repeated_sEMG = np.repeat(y_train, X_train_sEMG.shape[1])\n",
    "    coef_sEMG, _ = spearmanr(sEMG_flat, y_repeated_sEMG[:len(sEMG_flat)])\n",
    "    correlations_sEMG.append(coef_sEMG)\n",
    "\n",
    "correlation_sEMG = np.mean(correlations_sEMG)\n",
    "\n",
    "all_correlations = []\n",
    "all_correlations.append(correlations_trunk[0])\n",
    "\n",
    "all_correlations.append(correlations_upper_limb[0])\n",
    "all_correlations.append(correlations_lower_limb[0])\n",
    "all_correlations.append(correlation_sEMG)\n",
    "\n",
    "\n",
    "# 打印相关性结果\n",
    "print(\"Correlations for Trunk:\", correlations_trunk)\n",
    "print(\"Correlations for Upper Limb:\", correlations_upper_limb)\n",
    "print(\"Correlations for Lower Limb:\", correlations_lower_limb)\n",
    "print(\"Correlations for sEMG signals:\", correlation_sEMG)\n",
    "print(\"Correlations for All:\", all_correlations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21777408 0.01896436 0.26326156 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate absolute values and normalize to get initial weights\n",
    "abs_correlations = np.abs(all_correlations)\n",
    "normalized_weights = abs_correlations / np.sum(abs_correlations)\n",
    "\n",
    "# Clip weights exceeding the threshold and redistribute if necessary\n",
    "max_threshold = 0.5\n",
    "clipped_weights = np.clip(normalized_weights, None, max_threshold)\n",
    "\n",
    "# Redistribute weights if any were clipped to the threshold\n",
    "if np.any(clipped_weights == max_threshold):\n",
    "    # Calculate the total weight to be redistributed among non-clipped weights\n",
    "    total_redistribute_weight = 1 - np.sum(clipped_weights == max_threshold) * max_threshold\n",
    "    # Calculate the sum of weights that are less than the threshold (these will be redistributed)\n",
    "    sum_weights_to_redistribute = np.sum(clipped_weights[clipped_weights < max_threshold])\n",
    "    # Adjust weights that are below the threshold\n",
    "    for i, weight in enumerate(clipped_weights):\n",
    "        if weight < max_threshold:\n",
    "            clipped_weights[i] = weight / sum_weights_to_redistribute * total_redistribute_weight\n",
    "\n",
    "print(clipped_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 0.6954 - binary_accuracy: 0.6664 - val_loss: 0.1532 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.1435 - binary_accuracy: 0.7877 - val_loss: 0.1461 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1385 - binary_accuracy: 0.7911 - val_loss: 0.1700 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1226 - binary_accuracy: 0.7927 - val_loss: 0.1475 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.1109 - binary_accuracy: 0.7981 - val_loss: 0.1196 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1016 - binary_accuracy: 0.8065 - val_loss: 0.0936 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0950 - binary_accuracy: 0.8087 - val_loss: 0.0897 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0892 - binary_accuracy: 0.8136 - val_loss: 0.0869 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0860 - binary_accuracy: 0.8482 - val_loss: 0.0718 - val_binary_accuracy: 0.9359 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0838 - binary_accuracy: 0.8518 - val_loss: 0.0746 - val_binary_accuracy: 0.9334 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1024 - binary_accuracy: 0.8318 - val_loss: 0.0890 - val_binary_accuracy: 0.8937 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0970 - binary_accuracy: 0.8220 - val_loss: 0.0795 - val_binary_accuracy: 0.9317 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0974 - binary_accuracy: 0.8350 - val_loss: 0.0731 - val_binary_accuracy: 0.9299 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0859 - binary_accuracy: 0.8528 - val_loss: 0.0724 - val_binary_accuracy: 0.9292 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0741 - binary_accuracy: 0.8709 - val_loss: 0.0778 - val_binary_accuracy: 0.9202 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0698 - binary_accuracy: 0.8747 - val_loss: 0.0789 - val_binary_accuracy: 0.9205 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0654 - binary_accuracy: 0.8791 - val_loss: 0.0784 - val_binary_accuracy: 0.9247 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0625 - binary_accuracy: 0.8923 - val_loss: 0.0784 - val_binary_accuracy: 0.9306 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0600 - binary_accuracy: 0.8990 - val_loss: 0.0792 - val_binary_accuracy: 0.9254 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0593 - binary_accuracy: 0.8972 - val_loss: 0.0805 - val_binary_accuracy: 0.9143 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0587 - binary_accuracy: 0.9056 - val_loss: 0.0798 - val_binary_accuracy: 0.9139 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0612 - binary_accuracy: 0.8933 - val_loss: 0.0874 - val_binary_accuracy: 0.9021 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0671 - binary_accuracy: 0.8697 - val_loss: 0.0821 - val_binary_accuracy: 0.9125 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0672 - binary_accuracy: 0.8941 - val_loss: 0.0848 - val_binary_accuracy: 0.9055 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0641 - binary_accuracy: 0.8861 - val_loss: 0.0840 - val_binary_accuracy: 0.8780 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0634 - binary_accuracy: 0.8871 - val_loss: 0.0913 - val_binary_accuracy: 0.8850 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0571 - binary_accuracy: 0.9006 - val_loss: 0.0935 - val_binary_accuracy: 0.8738 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0543 - binary_accuracy: 0.9048 - val_loss: 0.1023 - val_binary_accuracy: 0.8710 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0525 - binary_accuracy: 0.9160 - val_loss: 0.1013 - val_binary_accuracy: 0.8710 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0516 - binary_accuracy: 0.9142 - val_loss: 0.1157 - val_binary_accuracy: 0.8560 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0507 - binary_accuracy: 0.9214 - val_loss: 0.1093 - val_binary_accuracy: 0.8484 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0502 - binary_accuracy: 0.9140 - val_loss: 0.1260 - val_binary_accuracy: 0.8372 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0497 - binary_accuracy: 0.9202 - val_loss: 0.1186 - val_binary_accuracy: 0.8466 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0490 - binary_accuracy: 0.9166 - val_loss: 0.1324 - val_binary_accuracy: 0.8282 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0478 - binary_accuracy: 0.9212 - val_loss: 0.1314 - val_binary_accuracy: 0.8337 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0471 - binary_accuracy: 0.9236 - val_loss: 0.1399 - val_binary_accuracy: 0.8170 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0467 - binary_accuracy: 0.9268 - val_loss: 0.1417 - val_binary_accuracy: 0.8184 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0467 - binary_accuracy: 0.9230 - val_loss: 0.1534 - val_binary_accuracy: 0.7842 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0464 - binary_accuracy: 0.9272 - val_loss: 0.1471 - val_binary_accuracy: 0.8146 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0461 - binary_accuracy: 0.9224 - val_loss: 0.1602 - val_binary_accuracy: 0.7808 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0453 - binary_accuracy: 0.9320 - val_loss: 0.1548 - val_binary_accuracy: 0.8090 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0450 - binary_accuracy: 0.9240 - val_loss: 0.1676 - val_binary_accuracy: 0.7720 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0449 - binary_accuracy: 0.9348 - val_loss: 0.1625 - val_binary_accuracy: 0.7923 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0451 - binary_accuracy: 0.9238 - val_loss: 0.1816 - val_binary_accuracy: 0.7260 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0444 - binary_accuracy: 0.9320 - val_loss: 0.1651 - val_binary_accuracy: 0.7832 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0445 - binary_accuracy: 0.9256 - val_loss: 0.1869 - val_binary_accuracy: 0.7180 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0442 - binary_accuracy: 0.9344 - val_loss: 0.1682 - val_binary_accuracy: 0.7804 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0442 - binary_accuracy: 0.9238 - val_loss: 0.1984 - val_binary_accuracy: 0.6971 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0436 - binary_accuracy: 0.9350 - val_loss: 0.1717 - val_binary_accuracy: 0.7769 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0435 - binary_accuracy: 0.9260 - val_loss: 0.1971 - val_binary_accuracy: 0.7135 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 0s 2ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83      2698\n",
      "           1       0.12      0.60      0.20       171\n",
      "\n",
      "    accuracy                           0.71      2869\n",
      "   macro avg       0.54      0.66      0.51      2869\n",
      "weighted avg       0.92      0.71      0.79      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[1945  753]\n",
      " [  69  102]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 0.3910 - binary_accuracy: 0.6608 - val_loss: 0.1194 - val_binary_accuracy: 0.9111 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.2895 - binary_accuracy: 0.6995 - val_loss: 0.1832 - val_binary_accuracy: 0.3775 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.1374 - binary_accuracy: 0.8095 - val_loss: 0.1232 - val_binary_accuracy: 0.7783 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.1132 - binary_accuracy: 0.8230 - val_loss: 0.2473 - val_binary_accuracy: 0.1199 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0915 - binary_accuracy: 0.8472 - val_loss: 0.1825 - val_binary_accuracy: 0.3695 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0853 - binary_accuracy: 0.8601 - val_loss: 0.1426 - val_binary_accuracy: 0.7327 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0727 - binary_accuracy: 0.8687 - val_loss: 0.0918 - val_binary_accuracy: 0.9296 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0812 - binary_accuracy: 0.8526 - val_loss: 0.1153 - val_binary_accuracy: 0.8059 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0853 - binary_accuracy: 0.8723 - val_loss: 0.1529 - val_binary_accuracy: 0.6846 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0872 - binary_accuracy: 0.8743 - val_loss: 0.1354 - val_binary_accuracy: 0.6762 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0747 - binary_accuracy: 0.8775 - val_loss: 0.0857 - val_binary_accuracy: 0.9275 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 0.0669 - binary_accuracy: 0.8863 - val_loss: 0.1034 - val_binary_accuracy: 0.8641 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 0.0568 - binary_accuracy: 0.9024 - val_loss: 0.0825 - val_binary_accuracy: 0.9139 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 0.0547 - binary_accuracy: 0.9052 - val_loss: 0.0730 - val_binary_accuracy: 0.9258 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0574 - binary_accuracy: 0.8933 - val_loss: 0.0636 - val_binary_accuracy: 0.9289 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0751 - binary_accuracy: 0.8921 - val_loss: 0.0890 - val_binary_accuracy: 0.8972 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0769 - binary_accuracy: 0.8727 - val_loss: 0.0679 - val_binary_accuracy: 0.9292 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0692 - binary_accuracy: 0.8811 - val_loss: 0.0902 - val_binary_accuracy: 0.9003 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0558 - binary_accuracy: 0.9116 - val_loss: 0.0545 - val_binary_accuracy: 0.9390 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0514 - binary_accuracy: 0.9104 - val_loss: 0.0713 - val_binary_accuracy: 0.9129 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0467 - binary_accuracy: 0.9208 - val_loss: 0.0639 - val_binary_accuracy: 0.9202 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0441 - binary_accuracy: 0.9298 - val_loss: 0.0675 - val_binary_accuracy: 0.8864 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0426 - binary_accuracy: 0.9286 - val_loss: 0.0659 - val_binary_accuracy: 0.9094 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0408 - binary_accuracy: 0.9334 - val_loss: 0.0667 - val_binary_accuracy: 0.8899 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0393 - binary_accuracy: 0.9385 - val_loss: 0.0632 - val_binary_accuracy: 0.8930 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0385 - binary_accuracy: 0.9374 - val_loss: 0.0742 - val_binary_accuracy: 0.8825 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0379 - binary_accuracy: 0.9431 - val_loss: 0.0635 - val_binary_accuracy: 0.8916 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0378 - binary_accuracy: 0.9360 - val_loss: 0.0742 - val_binary_accuracy: 0.8860 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0377 - binary_accuracy: 0.9407 - val_loss: 0.0679 - val_binary_accuracy: 0.8933 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0380 - binary_accuracy: 0.9354 - val_loss: 0.0760 - val_binary_accuracy: 0.8857 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0375 - binary_accuracy: 0.9441 - val_loss: 0.0701 - val_binary_accuracy: 0.8926 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0365 - binary_accuracy: 0.9379 - val_loss: 0.0780 - val_binary_accuracy: 0.8867 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0346 - binary_accuracy: 0.9519 - val_loss: 0.0755 - val_binary_accuracy: 0.8686 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 0.0329 - binary_accuracy: 0.9477 - val_loss: 0.0842 - val_binary_accuracy: 0.8595 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0318 - binary_accuracy: 0.9551 - val_loss: 0.0820 - val_binary_accuracy: 0.8588 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0312 - binary_accuracy: 0.9513 - val_loss: 0.0881 - val_binary_accuracy: 0.8578 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0304 - binary_accuracy: 0.9543 - val_loss: 0.0930 - val_binary_accuracy: 0.8508 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0299 - binary_accuracy: 0.9589 - val_loss: 0.0936 - val_binary_accuracy: 0.8522 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0295 - binary_accuracy: 0.9557 - val_loss: 0.1003 - val_binary_accuracy: 0.8491 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0290 - binary_accuracy: 0.9591 - val_loss: 0.1014 - val_binary_accuracy: 0.8487 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0286 - binary_accuracy: 0.9625 - val_loss: 0.1045 - val_binary_accuracy: 0.8470 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0282 - binary_accuracy: 0.9599 - val_loss: 0.1120 - val_binary_accuracy: 0.8452 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 0.0278 - binary_accuracy: 0.9629 - val_loss: 0.1109 - val_binary_accuracy: 0.8459 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0275 - binary_accuracy: 0.9613 - val_loss: 0.1175 - val_binary_accuracy: 0.8442 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0272 - binary_accuracy: 0.9613 - val_loss: 0.1163 - val_binary_accuracy: 0.8456 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0270 - binary_accuracy: 0.9635 - val_loss: 0.1225 - val_binary_accuracy: 0.8432 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0267 - binary_accuracy: 0.9627 - val_loss: 0.1219 - val_binary_accuracy: 0.8432 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0264 - binary_accuracy: 0.9643 - val_loss: 0.1260 - val_binary_accuracy: 0.8425 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0262 - binary_accuracy: 0.9635 - val_loss: 0.1263 - val_binary_accuracy: 0.8414 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0259 - binary_accuracy: 0.9643 - val_loss: 0.1315 - val_binary_accuracy: 0.8407 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      2698\n",
      "           1       0.19      0.52      0.28       171\n",
      "\n",
      "    accuracy                           0.84      2869\n",
      "   macro avg       0.58      0.69      0.60      2869\n",
      "weighted avg       0.92      0.84      0.87      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2323  375]\n",
      " [  82   89]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 0.3821 - binary_accuracy: 0.6367 - val_loss: 0.2199 - val_binary_accuracy: 0.7337 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.2784 - binary_accuracy: 0.5954 - val_loss: 0.1429 - val_binary_accuracy: 0.6720 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1376 - binary_accuracy: 0.7370 - val_loss: 0.1047 - val_binary_accuracy: 0.9129 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.1293 - binary_accuracy: 0.7901 - val_loss: 0.1243 - val_binary_accuracy: 0.9278 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1090 - binary_accuracy: 0.8172 - val_loss: 0.1084 - val_binary_accuracy: 0.9146 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1039 - binary_accuracy: 0.8190 - val_loss: 0.0878 - val_binary_accuracy: 0.9380 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0970 - binary_accuracy: 0.8310 - val_loss: 0.1080 - val_binary_accuracy: 0.9041 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0911 - binary_accuracy: 0.8520 - val_loss: 0.1009 - val_binary_accuracy: 0.9265 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0848 - binary_accuracy: 0.8651 - val_loss: 0.0859 - val_binary_accuracy: 0.9157 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0815 - binary_accuracy: 0.8819 - val_loss: 0.0817 - val_binary_accuracy: 0.9209 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0800 - binary_accuracy: 0.8761 - val_loss: 0.0929 - val_binary_accuracy: 0.9104 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0727 - binary_accuracy: 0.8925 - val_loss: 0.0958 - val_binary_accuracy: 0.9195 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0714 - binary_accuracy: 0.8915 - val_loss: 0.0698 - val_binary_accuracy: 0.9362 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0720 - binary_accuracy: 0.8811 - val_loss: 0.0806 - val_binary_accuracy: 0.9132 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0844 - binary_accuracy: 0.8807 - val_loss: 0.1064 - val_binary_accuracy: 0.8550 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0799 - binary_accuracy: 0.8803 - val_loss: 0.0771 - val_binary_accuracy: 0.9028 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0678 - binary_accuracy: 0.8951 - val_loss: 0.0876 - val_binary_accuracy: 0.9017 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0674 - binary_accuracy: 0.9012 - val_loss: 0.1167 - val_binary_accuracy: 0.8048 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0647 - binary_accuracy: 0.8917 - val_loss: 0.0998 - val_binary_accuracy: 0.8648 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0658 - binary_accuracy: 0.8911 - val_loss: 0.0952 - val_binary_accuracy: 0.8745 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0707 - binary_accuracy: 0.8929 - val_loss: 0.0765 - val_binary_accuracy: 0.8846 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0633 - binary_accuracy: 0.9064 - val_loss: 0.0817 - val_binary_accuracy: 0.8770 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0615 - binary_accuracy: 0.9096 - val_loss: 0.1120 - val_binary_accuracy: 0.8240 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0590 - binary_accuracy: 0.9076 - val_loss: 0.1006 - val_binary_accuracy: 0.8362 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0554 - binary_accuracy: 0.9122 - val_loss: 0.1238 - val_binary_accuracy: 0.7951 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0532 - binary_accuracy: 0.9162 - val_loss: 0.1470 - val_binary_accuracy: 0.7449 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0508 - binary_accuracy: 0.9178 - val_loss: 0.1456 - val_binary_accuracy: 0.7898 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0490 - binary_accuracy: 0.9306 - val_loss: 0.1308 - val_binary_accuracy: 0.8010 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0481 - binary_accuracy: 0.9256 - val_loss: 0.1414 - val_binary_accuracy: 0.7867 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0467 - binary_accuracy: 0.9276 - val_loss: 0.1569 - val_binary_accuracy: 0.7483 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0463 - binary_accuracy: 0.9264 - val_loss: 0.1404 - val_binary_accuracy: 0.8027 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0470 - binary_accuracy: 0.9288 - val_loss: 0.1390 - val_binary_accuracy: 0.8010 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0460 - binary_accuracy: 0.9198 - val_loss: 0.1533 - val_binary_accuracy: 0.7884 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0440 - binary_accuracy: 0.9326 - val_loss: 0.1268 - val_binary_accuracy: 0.8163 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0433 - binary_accuracy: 0.9326 - val_loss: 0.1718 - val_binary_accuracy: 0.7396 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0424 - binary_accuracy: 0.9379 - val_loss: 0.1431 - val_binary_accuracy: 0.7895 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0432 - binary_accuracy: 0.9340 - val_loss: 0.1810 - val_binary_accuracy: 0.7361 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0431 - binary_accuracy: 0.9352 - val_loss: 0.1421 - val_binary_accuracy: 0.8024 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0435 - binary_accuracy: 0.9338 - val_loss: 0.1780 - val_binary_accuracy: 0.7330 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0419 - binary_accuracy: 0.9340 - val_loss: 0.1393 - val_binary_accuracy: 0.8104 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 0.0407 - binary_accuracy: 0.9405 - val_loss: 0.1671 - val_binary_accuracy: 0.7637 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0393 - binary_accuracy: 0.9409 - val_loss: 0.1633 - val_binary_accuracy: 0.7717 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0383 - binary_accuracy: 0.9429 - val_loss: 0.1704 - val_binary_accuracy: 0.7417 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0377 - binary_accuracy: 0.9463 - val_loss: 0.1633 - val_binary_accuracy: 0.7727 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0372 - binary_accuracy: 0.9451 - val_loss: 0.1772 - val_binary_accuracy: 0.7396 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0369 - binary_accuracy: 0.9453 - val_loss: 0.1594 - val_binary_accuracy: 0.7808 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0366 - binary_accuracy: 0.9457 - val_loss: 0.1718 - val_binary_accuracy: 0.7410 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0362 - binary_accuracy: 0.9439 - val_loss: 0.1653 - val_binary_accuracy: 0.7476 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0359 - binary_accuracy: 0.9461 - val_loss: 0.1619 - val_binary_accuracy: 0.7679 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0357 - binary_accuracy: 0.9477 - val_loss: 0.1704 - val_binary_accuracy: 0.7456 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85      2698\n",
      "           1       0.09      0.35      0.14       171\n",
      "\n",
      "    accuracy                           0.75      2869\n",
      "   macro avg       0.52      0.56      0.50      2869\n",
      "weighted avg       0.90      0.75      0.81      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2079  619]\n",
      " [ 111   60]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 0.3411 - binary_accuracy: 0.6782 - val_loss: 0.1775 - val_binary_accuracy: 0.0596 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.1526 - binary_accuracy: 0.7378 - val_loss: 0.1595 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.1166 - binary_accuracy: 0.8071 - val_loss: 0.1515 - val_binary_accuracy: 0.9397 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.1146 - binary_accuracy: 0.8136 - val_loss: 0.1411 - val_binary_accuracy: 0.9397 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.1086 - binary_accuracy: 0.8196 - val_loss: 0.1345 - val_binary_accuracy: 0.9390 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.1042 - binary_accuracy: 0.8226 - val_loss: 0.1423 - val_binary_accuracy: 0.9428 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1015 - binary_accuracy: 0.8282 - val_loss: 0.1295 - val_binary_accuracy: 0.9411 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0964 - binary_accuracy: 0.8348 - val_loss: 0.1250 - val_binary_accuracy: 0.9428 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0930 - binary_accuracy: 0.8358 - val_loss: 0.1235 - val_binary_accuracy: 0.9397 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0908 - binary_accuracy: 0.8414 - val_loss: 0.1189 - val_binary_accuracy: 0.9407 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0880 - binary_accuracy: 0.8430 - val_loss: 0.0906 - val_binary_accuracy: 0.9421 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0815 - binary_accuracy: 0.8488 - val_loss: 0.0847 - val_binary_accuracy: 0.9421 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0771 - binary_accuracy: 0.8571 - val_loss: 0.0906 - val_binary_accuracy: 0.9397 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0762 - binary_accuracy: 0.8653 - val_loss: 0.0622 - val_binary_accuracy: 0.9428 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0712 - binary_accuracy: 0.8695 - val_loss: 0.0598 - val_binary_accuracy: 0.9421 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0676 - binary_accuracy: 0.8785 - val_loss: 0.0560 - val_binary_accuracy: 0.9421 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0657 - binary_accuracy: 0.8865 - val_loss: 0.0475 - val_binary_accuracy: 0.9421 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.0618 - binary_accuracy: 0.8885 - val_loss: 0.0458 - val_binary_accuracy: 0.9418 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0593 - binary_accuracy: 0.8962 - val_loss: 0.0445 - val_binary_accuracy: 0.9418 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0586 - binary_accuracy: 0.9018 - val_loss: 0.0445 - val_binary_accuracy: 0.9421 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0553 - binary_accuracy: 0.9008 - val_loss: 0.0431 - val_binary_accuracy: 0.9394 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0564 - binary_accuracy: 0.9090 - val_loss: 0.0497 - val_binary_accuracy: 0.9421 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0530 - binary_accuracy: 0.9094 - val_loss: 0.0467 - val_binary_accuracy: 0.9397 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0521 - binary_accuracy: 0.9162 - val_loss: 0.0554 - val_binary_accuracy: 0.9414 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0484 - binary_accuracy: 0.9148 - val_loss: 0.0497 - val_binary_accuracy: 0.9397 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0486 - binary_accuracy: 0.9252 - val_loss: 0.0601 - val_binary_accuracy: 0.9407 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0451 - binary_accuracy: 0.9278 - val_loss: 0.0571 - val_binary_accuracy: 0.9400 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0439 - binary_accuracy: 0.9276 - val_loss: 0.0645 - val_binary_accuracy: 0.9400 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0419 - binary_accuracy: 0.9368 - val_loss: 0.0612 - val_binary_accuracy: 0.9394 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0395 - binary_accuracy: 0.9360 - val_loss: 0.0636 - val_binary_accuracy: 0.9400 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0382 - binary_accuracy: 0.9443 - val_loss: 0.0686 - val_binary_accuracy: 0.9400 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0362 - binary_accuracy: 0.9469 - val_loss: 0.0661 - val_binary_accuracy: 0.9383 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0348 - binary_accuracy: 0.9501 - val_loss: 0.0677 - val_binary_accuracy: 0.9394 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0336 - binary_accuracy: 0.9557 - val_loss: 0.0706 - val_binary_accuracy: 0.9390 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0324 - binary_accuracy: 0.9563 - val_loss: 0.0706 - val_binary_accuracy: 0.9390 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0316 - binary_accuracy: 0.9579 - val_loss: 0.0702 - val_binary_accuracy: 0.9387 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0306 - binary_accuracy: 0.9601 - val_loss: 0.0724 - val_binary_accuracy: 0.9390 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0295 - binary_accuracy: 0.9611 - val_loss: 0.0708 - val_binary_accuracy: 0.9376 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0288 - binary_accuracy: 0.9621 - val_loss: 0.0731 - val_binary_accuracy: 0.9373 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0279 - binary_accuracy: 0.9649 - val_loss: 0.0746 - val_binary_accuracy: 0.9366 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0269 - binary_accuracy: 0.9663 - val_loss: 0.0753 - val_binary_accuracy: 0.9376 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0259 - binary_accuracy: 0.9675 - val_loss: 0.0760 - val_binary_accuracy: 0.9376 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0255 - binary_accuracy: 0.9705 - val_loss: 0.0769 - val_binary_accuracy: 0.9366 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 0.0245 - binary_accuracy: 0.9719 - val_loss: 0.0753 - val_binary_accuracy: 0.9334 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0239 - binary_accuracy: 0.9735 - val_loss: 0.0753 - val_binary_accuracy: 0.9306 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0232 - binary_accuracy: 0.9747 - val_loss: 0.0758 - val_binary_accuracy: 0.9285 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0229 - binary_accuracy: 0.9771 - val_loss: 0.0773 - val_binary_accuracy: 0.9244 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0223 - binary_accuracy: 0.9769 - val_loss: 0.0767 - val_binary_accuracy: 0.9223 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0217 - binary_accuracy: 0.9789 - val_loss: 0.0784 - val_binary_accuracy: 0.9216 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0213 - binary_accuracy: 0.9794 - val_loss: 0.0780 - val_binary_accuracy: 0.9205 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 0s 3ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      2698\n",
      "           1       0.36      0.43      0.39       171\n",
      "\n",
      "    accuracy                           0.92      2869\n",
      "   macro avg       0.66      0.69      0.68      2869\n",
      "weighted avg       0.93      0.92      0.92      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2567  131]\n",
      " [  97   74]]\n"
     ]
    }
   ],
   "source": [
    "# Modality groups definition\n",
    "trunk_indices = [0, 7, 8, 19, 20, 21]\n",
    "upper_limb_indices = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "lower_limb_indices = [1, 2, 3, 4, 5, 6]\n",
    "sEMG_indices = list(range(66, 70))\n",
    "\n",
    "# Function to prepare modality-specific datasets\n",
    "def prepare_modality_data(X, indices, is_sEMG=False):\n",
    "    if is_sEMG:\n",
    "        return X[:, :, indices]\n",
    "    else:\n",
    "        all_indices = []\n",
    "        for i in indices:\n",
    "            all_indices.extend([i, i+22, i+44])\n",
    "        return X[:, :, all_indices]\n",
    "\n",
    "# Define modalities\n",
    "modalities = {\n",
    "    \"Trunk\": trunk_indices,\n",
    "    \"Upper Limb\": upper_limb_indices,\n",
    "    \"Lower Limb\": lower_limb_indices,\n",
    "    \"sEMG\": sEMG_indices\n",
    "}\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for modality_name, indices in modalities.items():\n",
    "    is_sEMG = (modality_name == \"sEMG\")\n",
    "    X_train_modality = prepare_modality_data(X_train, indices, is_sEMG)\n",
    "    X_valid_modality = prepare_modality_data(X_valid, indices, is_sEMG)\n",
    "\n",
    "    input_shape = (X_train_modality.shape[1], X_train_modality.shape[2])\n",
    "    model = cnn_normal(input_shape)  # Use cnn_normal instead of stacked_lstm\n",
    "    y_pred_modality, y_true_modality, _ = model_pipeline(model, X_train_modality, y_train, X_valid_modality, y_valid)\n",
    "\n",
    "    predictions[modality_name] = y_pred_modality\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9320320669222726\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      2698\n",
      "           1       0.42      0.36      0.38       171\n",
      "\n",
      "    accuracy                           0.93      2869\n",
      "   macro avg       0.69      0.66      0.67      2869\n",
      "weighted avg       0.93      0.93      0.93      2869\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2613   85]\n",
      " [ 110   61]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "predictions_list = [predictions[modality] for modality in modalities.keys()]\n",
    "\n",
    "weighted_predictions = np.zeros(predictions_list[0].shape)\n",
    "\n",
    "# Apply the clipped and redistributed weights to the predictions\n",
    "for i, prediction in enumerate(predictions_list):\n",
    "    # print(clipped_weights[i])\n",
    "    weighted_predictions += prediction * clipped_weights[i]\n",
    "    # weighted_predictions += prediction / 4\n",
    "\n",
    "# print(weighted_predictions)\n",
    "\n",
    "\n",
    "final_predictions = np.round(weighted_predictions)\n",
    "\n",
    "# Convert y_valid to class indices if it's in one-hot encoding\n",
    "y_valid_indices = np.argmax(y_valid, axis=1)\n",
    "\n",
    "# Evaluate the combined predictions\n",
    "accuracy = accuracy_score(y_valid_indices, final_predictions)\n",
    "classification_report_result = classification_report(y_valid_indices, final_predictions)\n",
    "confusion_matrix_result = confusion_matrix(y_valid_indices, final_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report_result)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, Activation, BatchNormalization, Multiply, GlobalAveragePooling1D, Permute, Reshape, concatenate\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def enhanced_cnn_with_attention(input_shape):\n",
    "    \"\"\"\n",
    "    Creates an enhanced 1D CNN model with attention mechanism and additional features for processing time series data.\n",
    "\n",
    "    Args:\n",
    "    input_shape (tuple): The shape of the input data, excluding the batch size.\n",
    "\n",
    "    Returns:\n",
    "    keras.engine.training.Model: An enhanced 1D CNN model with attention.\n",
    "    \"\"\"\n",
    "    input_data = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layer block 1\n",
    "    x = Conv1D(32, 5, padding='same')(input_data)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(32, 5, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Convolutional layer block 2\n",
    "    x = Conv1D(64, 5, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(64, 5, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Convolutional layer block 3\n",
    "    x = Conv1D(128, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(128, 3, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Attention Mechanism\n",
    "    attention_probs = Dense(128, activation='softmax', name='attention_vec')(x)\n",
    "    attention_mul = Multiply()([x, attention_probs])\n",
    "\n",
    "    # Global Average Pooling\n",
    "    x = GlobalAveragePooling1D()(attention_mul)\n",
    "\n",
    "    # Additional Dense Layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    out = Dense(2, activation='softmax')(x)  # Assuming a binary classification task\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=out)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 123ms/step - loss: 0.1630 - binary_accuracy: 0.7382 - val_loss: 0.1035 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.1350 - binary_accuracy: 0.7899 - val_loss: 0.1001 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.1295 - binary_accuracy: 0.7899 - val_loss: 0.1020 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.1271 - binary_accuracy: 0.7899 - val_loss: 0.1019 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.1241 - binary_accuracy: 0.7899 - val_loss: 0.1066 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.1182 - binary_accuracy: 0.7899 - val_loss: 0.1192 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.1098 - binary_accuracy: 0.7899 - val_loss: 0.1327 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.1140 - binary_accuracy: 0.7899 - val_loss: 0.1058 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.1175 - binary_accuracy: 0.7899 - val_loss: 0.0759 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.1151 - binary_accuracy: 0.7895 - val_loss: 0.1010 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.1063 - binary_accuracy: 0.8053 - val_loss: 0.0689 - val_binary_accuracy: 0.9275 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.1050 - binary_accuracy: 0.8170 - val_loss: 0.0909 - val_binary_accuracy: 0.9345 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.0951 - binary_accuracy: 0.8378 - val_loss: 0.1177 - val_binary_accuracy: 0.7306 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0904 - binary_accuracy: 0.8490 - val_loss: 0.0837 - val_binary_accuracy: 0.8933 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.0830 - binary_accuracy: 0.8597 - val_loss: 0.1104 - val_binary_accuracy: 0.8041 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0829 - binary_accuracy: 0.8534 - val_loss: 0.1273 - val_binary_accuracy: 0.6818 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.0851 - binary_accuracy: 0.8567 - val_loss: 0.0592 - val_binary_accuracy: 0.9324 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0842 - binary_accuracy: 0.8619 - val_loss: 0.0577 - val_binary_accuracy: 0.9303 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.0770 - binary_accuracy: 0.8769 - val_loss: 0.0597 - val_binary_accuracy: 0.9362 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.0772 - binary_accuracy: 0.8709 - val_loss: 0.0625 - val_binary_accuracy: 0.9380 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.0724 - binary_accuracy: 0.8829 - val_loss: 0.0573 - val_binary_accuracy: 0.9198 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0707 - binary_accuracy: 0.8881 - val_loss: 0.0570 - val_binary_accuracy: 0.9359 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0639 - binary_accuracy: 0.8933 - val_loss: 0.0755 - val_binary_accuracy: 0.8682 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0666 - binary_accuracy: 0.8968 - val_loss: 0.0665 - val_binary_accuracy: 0.8902 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0619 - binary_accuracy: 0.8982 - val_loss: 0.0725 - val_binary_accuracy: 0.8902 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0626 - binary_accuracy: 0.9000 - val_loss: 0.0958 - val_binary_accuracy: 0.8853 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0584 - binary_accuracy: 0.9046 - val_loss: 0.1500 - val_binary_accuracy: 0.8243 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0606 - binary_accuracy: 0.9020 - val_loss: 0.1498 - val_binary_accuracy: 0.8710 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0563 - binary_accuracy: 0.9044 - val_loss: 0.1503 - val_binary_accuracy: 0.8658 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0553 - binary_accuracy: 0.9104 - val_loss: 0.2127 - val_binary_accuracy: 0.8341 - lr: 3.5849e-04\n",
      "90/90 [==============================] - 1s 5ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      2698\n",
      "           1       0.18      0.49      0.26       171\n",
      "\n",
      "    accuracy                           0.83      2869\n",
      "   macro avg       0.57      0.67      0.58      2869\n",
      "weighted avg       0.92      0.83      0.87      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2309  389]\n",
      " [  87   84]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 104ms/step - loss: 0.1616 - binary_accuracy: 0.7380 - val_loss: 0.1296 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.1337 - binary_accuracy: 0.7899 - val_loss: 0.1053 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 0.1209 - binary_accuracy: 0.7899 - val_loss: 0.1109 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.1180 - binary_accuracy: 0.7899 - val_loss: 0.1173 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 0.1149 - binary_accuracy: 0.7931 - val_loss: 0.1135 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 0.1124 - binary_accuracy: 0.8057 - val_loss: 0.1113 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.1090 - binary_accuracy: 0.8136 - val_loss: 0.1097 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.1061 - binary_accuracy: 0.8109 - val_loss: 0.1016 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.1036 - binary_accuracy: 0.8142 - val_loss: 0.1037 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.1018 - binary_accuracy: 0.8176 - val_loss: 0.0915 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.0983 - binary_accuracy: 0.8182 - val_loss: 0.0835 - val_binary_accuracy: 0.9376 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.0976 - binary_accuracy: 0.8172 - val_loss: 0.0777 - val_binary_accuracy: 0.9404 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0930 - binary_accuracy: 0.8252 - val_loss: 0.0735 - val_binary_accuracy: 0.9369 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0901 - binary_accuracy: 0.8276 - val_loss: 0.0644 - val_binary_accuracy: 0.9369 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0886 - binary_accuracy: 0.8376 - val_loss: 0.0621 - val_binary_accuracy: 0.9404 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.0885 - binary_accuracy: 0.8418 - val_loss: 0.0630 - val_binary_accuracy: 0.9394 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 0.0862 - binary_accuracy: 0.8410 - val_loss: 0.0591 - val_binary_accuracy: 0.9404 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0855 - binary_accuracy: 0.8398 - val_loss: 0.0581 - val_binary_accuracy: 0.9369 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0847 - binary_accuracy: 0.8466 - val_loss: 0.0462 - val_binary_accuracy: 0.9387 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.0822 - binary_accuracy: 0.8526 - val_loss: 0.0462 - val_binary_accuracy: 0.9418 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.0825 - binary_accuracy: 0.8561 - val_loss: 0.0452 - val_binary_accuracy: 0.9404 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0809 - binary_accuracy: 0.8577 - val_loss: 0.0446 - val_binary_accuracy: 0.9414 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 1s 95ms/step - loss: 0.0818 - binary_accuracy: 0.8547 - val_loss: 0.0471 - val_binary_accuracy: 0.9397 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0798 - binary_accuracy: 0.8603 - val_loss: 0.0477 - val_binary_accuracy: 0.9397 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0724 - binary_accuracy: 0.8771 - val_loss: 0.0452 - val_binary_accuracy: 0.9394 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0717 - binary_accuracy: 0.8823 - val_loss: 0.0459 - val_binary_accuracy: 0.9394 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.0682 - binary_accuracy: 0.8857 - val_loss: 0.0458 - val_binary_accuracy: 0.9376 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.0684 - binary_accuracy: 0.8845 - val_loss: 0.0477 - val_binary_accuracy: 0.9376 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.0681 - binary_accuracy: 0.8893 - val_loss: 0.0483 - val_binary_accuracy: 0.9369 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.0667 - binary_accuracy: 0.8883 - val_loss: 0.0472 - val_binary_accuracy: 0.9334 - lr: 3.5849e-04\n",
      "90/90 [==============================] - 0s 5ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      2698\n",
      "           1       0.42      0.29      0.34       171\n",
      "\n",
      "    accuracy                           0.93      2869\n",
      "   macro avg       0.69      0.63      0.65      2869\n",
      "weighted avg       0.92      0.93      0.93      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2628   70]\n",
      " [ 121   50]]\n"
     ]
    }
   ],
   "source": [
    "#分割成两个模态\n",
    "model_pose = enhanced_cnn_with_attention(input_shape=(180, 66))\n",
    "y_pred_pose, y_true_pose, H_pose = model_pipeline(model_pose, X_train_pose, y_train, X_valid_pose, y_valid, epoch=30)\n",
    "\n",
    "model_sEMG = enhanced_cnn_with_attention(input_shape=(180, 4))\n",
    "y_pred_sEMG, y_true_sEMG, H_sEMG = model_pipeline(model_sEMG, X_train_sEMG, y_train, X_valid_sEMG, y_valid, epoch=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      2698\n",
      "           1       0.18      0.49      0.26       171\n",
      "\n",
      "    accuracy                           0.83      2869\n",
      "   macro avg       0.57      0.67      0.58      2869\n",
      "weighted avg       0.92      0.83      0.87      2869\n",
      "\n",
      "[[2309  389]\n",
      " [  87   84]]\n"
     ]
    }
   ],
   "source": [
    "weight_pose = normalized_weights[0]\n",
    "weight_sEMG = normalized_weights[1]\n",
    "\n",
    "\n",
    "final_pred = (y_pred_pose * weight_pose + y_pred_sEMG * weight_sEMG) / (weight_pose + weight_sEMG)\n",
    "final_pred = np.round(final_pred).astype(int)\n",
    "\n",
    "\n",
    "print(classification_report(y_true_pose, final_pred))\n",
    "print(confusion_matrix(y_true_pose, final_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/30\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 0.1637 - binary_accuracy: 0.7392 - val_loss: 0.0933 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.1360 - binary_accuracy: 0.7899 - val_loss: 0.0939 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.1284 - binary_accuracy: 0.7899 - val_loss: 0.1018 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.1255 - binary_accuracy: 0.7899 - val_loss: 0.1050 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.1241 - binary_accuracy: 0.7899 - val_loss: 0.1156 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.1176 - binary_accuracy: 0.7899 - val_loss: 0.1176 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.1153 - binary_accuracy: 0.7899 - val_loss: 0.0980 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.1155 - binary_accuracy: 0.7899 - val_loss: 0.1436 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.1095 - binary_accuracy: 0.7899 - val_loss: 0.1036 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.1029 - binary_accuracy: 0.7957 - val_loss: 0.1122 - val_binary_accuracy: 0.7264 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 0.0985 - binary_accuracy: 0.8304 - val_loss: 0.1304 - val_binary_accuracy: 0.5455 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0944 - binary_accuracy: 0.8464 - val_loss: 0.1626 - val_binary_accuracy: 0.3709 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0896 - binary_accuracy: 0.8478 - val_loss: 0.1586 - val_binary_accuracy: 0.4301 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.0894 - binary_accuracy: 0.8482 - val_loss: 0.0725 - val_binary_accuracy: 0.8425 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0892 - binary_accuracy: 0.8488 - val_loss: 0.1419 - val_binary_accuracy: 0.6159 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0822 - binary_accuracy: 0.8647 - val_loss: 0.1848 - val_binary_accuracy: 0.4190 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0760 - binary_accuracy: 0.8759 - val_loss: 0.1475 - val_binary_accuracy: 0.6159 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0740 - binary_accuracy: 0.8781 - val_loss: 0.1057 - val_binary_accuracy: 0.7752 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0695 - binary_accuracy: 0.8911 - val_loss: 0.1393 - val_binary_accuracy: 0.6877 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0667 - binary_accuracy: 0.8877 - val_loss: 0.1337 - val_binary_accuracy: 0.7048 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0667 - binary_accuracy: 0.8943 - val_loss: 0.2085 - val_binary_accuracy: 0.5333 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.0668 - binary_accuracy: 0.8857 - val_loss: 0.1039 - val_binary_accuracy: 0.8428 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.0677 - binary_accuracy: 0.8867 - val_loss: 0.1358 - val_binary_accuracy: 0.7752 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0625 - binary_accuracy: 0.8988 - val_loss: 0.1539 - val_binary_accuracy: 0.7888 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0619 - binary_accuracy: 0.8978 - val_loss: 0.2315 - val_binary_accuracy: 0.7191 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 0.0695 - binary_accuracy: 0.8869 - val_loss: 0.1765 - val_binary_accuracy: 0.7518 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0558 - binary_accuracy: 0.9128 - val_loss: 0.1933 - val_binary_accuracy: 0.7016 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0520 - binary_accuracy: 0.9154 - val_loss: 0.2242 - val_binary_accuracy: 0.6995 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.0492 - binary_accuracy: 0.9224 - val_loss: 0.3071 - val_binary_accuracy: 0.6037 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0476 - binary_accuracy: 0.9264 - val_loss: 0.3052 - val_binary_accuracy: 0.6344 - lr: 3.5849e-04\n",
      "90/90 [==============================] - 1s 5ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.64      0.77      2698\n",
      "           1       0.10      0.62      0.17       171\n",
      "\n",
      "    accuracy                           0.63      2869\n",
      "   macro avg       0.53      0.63      0.47      2869\n",
      "weighted avg       0.91      0.63      0.73      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[1714  984]\n",
      " [  65  106]]\n"
     ]
    }
   ],
   "source": [
    "#打包一起训练\n",
    "model = enhanced_cnn_with_attention(input_shape=(180, 70))\n",
    "y_pred, y_true, H = model_pipeline(model, X_train, y_train, X_valid, y_valid, epoch=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 2s 107ms/step - loss: 0.1629 - binary_accuracy: 0.7257 - val_loss: 0.1214 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.1369 - binary_accuracy: 0.7899 - val_loss: 0.0975 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.1276 - binary_accuracy: 0.7899 - val_loss: 0.1018 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.1255 - binary_accuracy: 0.7899 - val_loss: 0.1014 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 0.1223 - binary_accuracy: 0.7899 - val_loss: 0.1142 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.1199 - binary_accuracy: 0.7899 - val_loss: 0.1028 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 0.1152 - binary_accuracy: 0.7899 - val_loss: 0.1024 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.1107 - binary_accuracy: 0.7889 - val_loss: 0.1032 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.1040 - binary_accuracy: 0.8222 - val_loss: 0.0819 - val_binary_accuracy: 0.9202 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.1030 - binary_accuracy: 0.8380 - val_loss: 0.0789 - val_binary_accuracy: 0.9007 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.1055 - binary_accuracy: 0.8334 - val_loss: 0.0692 - val_binary_accuracy: 0.9111 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.1061 - binary_accuracy: 0.8190 - val_loss: 0.1903 - val_binary_accuracy: 0.3566 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0976 - binary_accuracy: 0.8494 - val_loss: 0.0746 - val_binary_accuracy: 0.8926 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0951 - binary_accuracy: 0.8396 - val_loss: 0.0958 - val_binary_accuracy: 0.8330 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0921 - binary_accuracy: 0.8418 - val_loss: 0.0730 - val_binary_accuracy: 0.8738 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0876 - binary_accuracy: 0.8571 - val_loss: 0.0778 - val_binary_accuracy: 0.8459 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0829 - binary_accuracy: 0.8663 - val_loss: 0.0740 - val_binary_accuracy: 0.9017 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0821 - binary_accuracy: 0.8645 - val_loss: 0.0681 - val_binary_accuracy: 0.9097 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0791 - binary_accuracy: 0.8649 - val_loss: 0.0662 - val_binary_accuracy: 0.9104 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0759 - binary_accuracy: 0.8731 - val_loss: 0.0815 - val_binary_accuracy: 0.9055 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0837 - binary_accuracy: 0.8589 - val_loss: 0.0766 - val_binary_accuracy: 0.9048 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0756 - binary_accuracy: 0.8717 - val_loss: 0.0719 - val_binary_accuracy: 0.9073 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0741 - binary_accuracy: 0.8737 - val_loss: 0.1038 - val_binary_accuracy: 0.8100 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0738 - binary_accuracy: 0.8727 - val_loss: 0.0742 - val_binary_accuracy: 0.8885 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0740 - binary_accuracy: 0.8729 - val_loss: 0.0794 - val_binary_accuracy: 0.8592 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0689 - binary_accuracy: 0.8791 - val_loss: 0.0780 - val_binary_accuracy: 0.8857 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0724 - binary_accuracy: 0.8763 - val_loss: 0.0791 - val_binary_accuracy: 0.8933 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0697 - binary_accuracy: 0.8777 - val_loss: 0.0836 - val_binary_accuracy: 0.8784 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0692 - binary_accuracy: 0.8807 - val_loss: 0.0984 - val_binary_accuracy: 0.8393 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0664 - binary_accuracy: 0.8855 - val_loss: 0.0927 - val_binary_accuracy: 0.8717 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0665 - binary_accuracy: 0.8827 - val_loss: 0.1338 - val_binary_accuracy: 0.7853 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0620 - binary_accuracy: 0.8929 - val_loss: 0.1246 - val_binary_accuracy: 0.8086 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0614 - binary_accuracy: 0.8913 - val_loss: 0.1263 - val_binary_accuracy: 0.8142 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0594 - binary_accuracy: 0.8939 - val_loss: 0.1222 - val_binary_accuracy: 0.8407 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0589 - binary_accuracy: 0.8970 - val_loss: 0.1154 - val_binary_accuracy: 0.8330 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0575 - binary_accuracy: 0.9002 - val_loss: 0.1335 - val_binary_accuracy: 0.7992 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0577 - binary_accuracy: 0.8972 - val_loss: 0.1233 - val_binary_accuracy: 0.8208 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0579 - binary_accuracy: 0.8972 - val_loss: 0.1270 - val_binary_accuracy: 0.8362 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0577 - binary_accuracy: 0.8937 - val_loss: 0.1566 - val_binary_accuracy: 0.8139 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0559 - binary_accuracy: 0.9006 - val_loss: 0.1669 - val_binary_accuracy: 0.7637 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0551 - binary_accuracy: 0.9016 - val_loss: 0.1513 - val_binary_accuracy: 0.8083 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0555 - binary_accuracy: 0.9042 - val_loss: 0.1528 - val_binary_accuracy: 0.7860 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0544 - binary_accuracy: 0.9044 - val_loss: 0.1436 - val_binary_accuracy: 0.8425 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0531 - binary_accuracy: 0.9088 - val_loss: 0.1592 - val_binary_accuracy: 0.8083 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0530 - binary_accuracy: 0.9074 - val_loss: 0.1770 - val_binary_accuracy: 0.7964 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0530 - binary_accuracy: 0.9068 - val_loss: 0.1947 - val_binary_accuracy: 0.7557 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0547 - binary_accuracy: 0.9066 - val_loss: 0.1657 - val_binary_accuracy: 0.8093 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0511 - binary_accuracy: 0.9122 - val_loss: 0.1724 - val_binary_accuracy: 0.7679 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0522 - binary_accuracy: 0.9096 - val_loss: 0.1693 - val_binary_accuracy: 0.7947 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0505 - binary_accuracy: 0.9118 - val_loss: 0.1854 - val_binary_accuracy: 0.7564 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 1s 5ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86      2698\n",
      "           1       0.08      0.28      0.12       171\n",
      "\n",
      "    accuracy                           0.76      2869\n",
      "   macro avg       0.51      0.53      0.49      2869\n",
      "weighted avg       0.89      0.76      0.81      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2122  576]\n",
      " [ 123   48]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 2s 115ms/step - loss: 0.1629 - binary_accuracy: 0.7688 - val_loss: 0.0972 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1365 - binary_accuracy: 0.7899 - val_loss: 0.0922 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.1297 - binary_accuracy: 0.7899 - val_loss: 0.0968 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.1273 - binary_accuracy: 0.7899 - val_loss: 0.0991 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1244 - binary_accuracy: 0.7899 - val_loss: 0.1054 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.1205 - binary_accuracy: 0.7899 - val_loss: 0.1180 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1110 - binary_accuracy: 0.7899 - val_loss: 0.1271 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1158 - binary_accuracy: 0.7899 - val_loss: 0.0847 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1076 - binary_accuracy: 0.7909 - val_loss: 0.0927 - val_binary_accuracy: 0.9355 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.1036 - binary_accuracy: 0.8156 - val_loss: 0.0841 - val_binary_accuracy: 0.8494 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1035 - binary_accuracy: 0.8244 - val_loss: 0.0841 - val_binary_accuracy: 0.8919 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0927 - binary_accuracy: 0.8500 - val_loss: 0.1052 - val_binary_accuracy: 0.8425 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0878 - binary_accuracy: 0.8619 - val_loss: 0.0928 - val_binary_accuracy: 0.9059 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0842 - binary_accuracy: 0.8607 - val_loss: 0.0838 - val_binary_accuracy: 0.9233 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0847 - binary_accuracy: 0.8506 - val_loss: 0.0794 - val_binary_accuracy: 0.9003 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0843 - binary_accuracy: 0.8591 - val_loss: 0.0933 - val_binary_accuracy: 0.8069 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.0816 - binary_accuracy: 0.8589 - val_loss: 0.0945 - val_binary_accuracy: 0.8139 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0740 - binary_accuracy: 0.8793 - val_loss: 0.0793 - val_binary_accuracy: 0.8665 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.0682 - binary_accuracy: 0.8843 - val_loss: 0.0894 - val_binary_accuracy: 0.8675 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0665 - binary_accuracy: 0.8966 - val_loss: 0.0770 - val_binary_accuracy: 0.8885 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0623 - binary_accuracy: 0.8958 - val_loss: 0.0657 - val_binary_accuracy: 0.8986 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0598 - binary_accuracy: 0.9064 - val_loss: 0.0714 - val_binary_accuracy: 0.9122 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0602 - binary_accuracy: 0.9018 - val_loss: 0.0638 - val_binary_accuracy: 0.9146 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0603 - binary_accuracy: 0.9036 - val_loss: 0.0690 - val_binary_accuracy: 0.9080 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0606 - binary_accuracy: 0.9002 - val_loss: 0.0758 - val_binary_accuracy: 0.9000 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0564 - binary_accuracy: 0.9122 - val_loss: 0.0707 - val_binary_accuracy: 0.9104 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0536 - binary_accuracy: 0.9122 - val_loss: 0.0752 - val_binary_accuracy: 0.9136 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0521 - binary_accuracy: 0.9172 - val_loss: 0.0733 - val_binary_accuracy: 0.9129 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0512 - binary_accuracy: 0.9156 - val_loss: 0.0755 - val_binary_accuracy: 0.9132 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.0507 - binary_accuracy: 0.9146 - val_loss: 0.0828 - val_binary_accuracy: 0.8940 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0515 - binary_accuracy: 0.9136 - val_loss: 0.0759 - val_binary_accuracy: 0.9167 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0492 - binary_accuracy: 0.9156 - val_loss: 0.0967 - val_binary_accuracy: 0.8554 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0481 - binary_accuracy: 0.9186 - val_loss: 0.0790 - val_binary_accuracy: 0.9108 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0463 - binary_accuracy: 0.9236 - val_loss: 0.1497 - val_binary_accuracy: 0.7633 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0461 - binary_accuracy: 0.9260 - val_loss: 0.0799 - val_binary_accuracy: 0.9080 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0464 - binary_accuracy: 0.9236 - val_loss: 0.2063 - val_binary_accuracy: 0.6950 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.0468 - binary_accuracy: 0.9170 - val_loss: 0.0713 - val_binary_accuracy: 0.9160 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0482 - binary_accuracy: 0.9230 - val_loss: 0.1273 - val_binary_accuracy: 0.8303 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0449 - binary_accuracy: 0.9294 - val_loss: 0.1370 - val_binary_accuracy: 0.7930 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0429 - binary_accuracy: 0.9302 - val_loss: 0.1272 - val_binary_accuracy: 0.8079 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0412 - binary_accuracy: 0.9342 - val_loss: 0.1307 - val_binary_accuracy: 0.7790 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0404 - binary_accuracy: 0.9354 - val_loss: 0.1974 - val_binary_accuracy: 0.7226 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0401 - binary_accuracy: 0.9336 - val_loss: 0.1628 - val_binary_accuracy: 0.7539 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0386 - binary_accuracy: 0.9377 - val_loss: 0.2307 - val_binary_accuracy: 0.7016 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0393 - binary_accuracy: 0.9348 - val_loss: 0.1746 - val_binary_accuracy: 0.7327 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0379 - binary_accuracy: 0.9395 - val_loss: 0.2536 - val_binary_accuracy: 0.6968 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0390 - binary_accuracy: 0.9413 - val_loss: 0.2597 - val_binary_accuracy: 0.6846 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0376 - binary_accuracy: 0.9439 - val_loss: 0.2822 - val_binary_accuracy: 0.6828 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0368 - binary_accuracy: 0.9437 - val_loss: 0.2887 - val_binary_accuracy: 0.6825 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0363 - binary_accuracy: 0.9417 - val_loss: 0.3032 - val_binary_accuracy: 0.6821 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 1s 5ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.68      0.80      2698\n",
      "           1       0.11      0.64      0.19       171\n",
      "\n",
      "    accuracy                           0.68      2869\n",
      "   macro avg       0.54      0.66      0.50      2869\n",
      "weighted avg       0.92      0.68      0.77      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[1848  850]\n",
      " [  62  109]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 2s 111ms/step - loss: 0.1662 - binary_accuracy: 0.7450 - val_loss: 0.1086 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1352 - binary_accuracy: 0.7899 - val_loss: 0.0963 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1289 - binary_accuracy: 0.7899 - val_loss: 0.1039 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1266 - binary_accuracy: 0.7899 - val_loss: 0.1066 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1261 - binary_accuracy: 0.7899 - val_loss: 0.1085 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.1243 - binary_accuracy: 0.7899 - val_loss: 0.1127 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1214 - binary_accuracy: 0.7899 - val_loss: 0.1149 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.1185 - binary_accuracy: 0.7899 - val_loss: 0.0722 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1258 - binary_accuracy: 0.7899 - val_loss: 0.1099 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.1167 - binary_accuracy: 0.7899 - val_loss: 0.1291 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.1149 - binary_accuracy: 0.7897 - val_loss: 0.1005 - val_binary_accuracy: 0.9404 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.1093 - binary_accuracy: 0.7967 - val_loss: 0.0915 - val_binary_accuracy: 0.9090 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1072 - binary_accuracy: 0.8212 - val_loss: 0.0948 - val_binary_accuracy: 0.8689 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1024 - binary_accuracy: 0.8316 - val_loss: 0.1191 - val_binary_accuracy: 0.7135 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0989 - binary_accuracy: 0.8274 - val_loss: 0.0850 - val_binary_accuracy: 0.8480 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.1029 - binary_accuracy: 0.8123 - val_loss: 0.0806 - val_binary_accuracy: 0.8351 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1014 - binary_accuracy: 0.8362 - val_loss: 0.1262 - val_binary_accuracy: 0.7466 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.1026 - binary_accuracy: 0.8166 - val_loss: 0.0754 - val_binary_accuracy: 0.8825 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0947 - binary_accuracy: 0.8412 - val_loss: 0.0861 - val_binary_accuracy: 0.8438 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0910 - binary_accuracy: 0.8563 - val_loss: 0.0893 - val_binary_accuracy: 0.8644 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0844 - binary_accuracy: 0.8743 - val_loss: 0.0867 - val_binary_accuracy: 0.8804 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0776 - binary_accuracy: 0.8835 - val_loss: 0.0857 - val_binary_accuracy: 0.8717 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0829 - binary_accuracy: 0.8717 - val_loss: 0.1130 - val_binary_accuracy: 0.8310 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0829 - binary_accuracy: 0.8731 - val_loss: 0.1446 - val_binary_accuracy: 0.7808 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.0785 - binary_accuracy: 0.8831 - val_loss: 0.1166 - val_binary_accuracy: 0.8616 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0750 - binary_accuracy: 0.8885 - val_loss: 0.1409 - val_binary_accuracy: 0.7954 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0817 - binary_accuracy: 0.8797 - val_loss: 0.1631 - val_binary_accuracy: 0.7260 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0732 - binary_accuracy: 0.8903 - val_loss: 0.1287 - val_binary_accuracy: 0.8749 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0673 - binary_accuracy: 0.9016 - val_loss: 0.1716 - val_binary_accuracy: 0.7989 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0679 - binary_accuracy: 0.8978 - val_loss: 0.1647 - val_binary_accuracy: 0.8027 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0727 - binary_accuracy: 0.8903 - val_loss: 0.1643 - val_binary_accuracy: 0.8111 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0703 - binary_accuracy: 0.8903 - val_loss: 0.2349 - val_binary_accuracy: 0.6947 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0664 - binary_accuracy: 0.8982 - val_loss: 0.2191 - val_binary_accuracy: 0.7456 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0628 - binary_accuracy: 0.9062 - val_loss: 0.2229 - val_binary_accuracy: 0.7334 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0611 - binary_accuracy: 0.9058 - val_loss: 0.2181 - val_binary_accuracy: 0.7815 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0605 - binary_accuracy: 0.9062 - val_loss: 0.2096 - val_binary_accuracy: 0.7487 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0590 - binary_accuracy: 0.9100 - val_loss: 0.2395 - val_binary_accuracy: 0.7135 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0576 - binary_accuracy: 0.9108 - val_loss: 0.2168 - val_binary_accuracy: 0.7734 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0569 - binary_accuracy: 0.9124 - val_loss: 0.2492 - val_binary_accuracy: 0.7407 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0576 - binary_accuracy: 0.9112 - val_loss: 0.2168 - val_binary_accuracy: 0.7602 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0562 - binary_accuracy: 0.9130 - val_loss: 0.2150 - val_binary_accuracy: 0.7661 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0557 - binary_accuracy: 0.9130 - val_loss: 0.2332 - val_binary_accuracy: 0.7473 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0551 - binary_accuracy: 0.9120 - val_loss: 0.2156 - val_binary_accuracy: 0.7787 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0568 - binary_accuracy: 0.9106 - val_loss: 0.2584 - val_binary_accuracy: 0.7016 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0560 - binary_accuracy: 0.9126 - val_loss: 0.1905 - val_binary_accuracy: 0.8013 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0547 - binary_accuracy: 0.9150 - val_loss: 0.2105 - val_binary_accuracy: 0.7846 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0529 - binary_accuracy: 0.9164 - val_loss: 0.2339 - val_binary_accuracy: 0.7738 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0513 - binary_accuracy: 0.9212 - val_loss: 0.2127 - val_binary_accuracy: 0.7933 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.0508 - binary_accuracy: 0.9224 - val_loss: 0.2266 - val_binary_accuracy: 0.7710 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0518 - binary_accuracy: 0.9164 - val_loss: 0.2179 - val_binary_accuracy: 0.7748 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 1s 5ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.80      0.87      2698\n",
      "           1       0.10      0.37      0.16       171\n",
      "\n",
      "    accuracy                           0.77      2869\n",
      "   macro avg       0.53      0.58      0.52      2869\n",
      "weighted avg       0.90      0.77      0.83      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2160  538]\n",
      " [ 108   63]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 2s 111ms/step - loss: 0.1574 - binary_accuracy: 0.7873 - val_loss: 0.1232 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1283 - binary_accuracy: 0.7899 - val_loss: 0.1114 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.1193 - binary_accuracy: 0.7899 - val_loss: 0.1178 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1157 - binary_accuracy: 0.7899 - val_loss: 0.1222 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.1143 - binary_accuracy: 0.7899 - val_loss: 0.1330 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.1103 - binary_accuracy: 0.7899 - val_loss: 0.1314 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.1062 - binary_accuracy: 0.7975 - val_loss: 0.1027 - val_binary_accuracy: 0.9387 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1023 - binary_accuracy: 0.8117 - val_loss: 0.0978 - val_binary_accuracy: 0.9376 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.1058 - binary_accuracy: 0.8130 - val_loss: 0.0497 - val_binary_accuracy: 0.9397 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1081 - binary_accuracy: 0.8053 - val_loss: 0.0671 - val_binary_accuracy: 0.9380 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.1100 - binary_accuracy: 0.8013 - val_loss: 0.0440 - val_binary_accuracy: 0.9407 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0958 - binary_accuracy: 0.8284 - val_loss: 0.0412 - val_binary_accuracy: 0.9407 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0953 - binary_accuracy: 0.8286 - val_loss: 0.0460 - val_binary_accuracy: 0.9411 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0901 - binary_accuracy: 0.8322 - val_loss: 0.0480 - val_binary_accuracy: 0.9414 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0893 - binary_accuracy: 0.8404 - val_loss: 0.0533 - val_binary_accuracy: 0.9418 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0889 - binary_accuracy: 0.8414 - val_loss: 0.0475 - val_binary_accuracy: 0.9400 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0879 - binary_accuracy: 0.8364 - val_loss: 0.0528 - val_binary_accuracy: 0.9414 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0860 - binary_accuracy: 0.8470 - val_loss: 0.0522 - val_binary_accuracy: 0.9407 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0826 - binary_accuracy: 0.8514 - val_loss: 0.0477 - val_binary_accuracy: 0.9400 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0850 - binary_accuracy: 0.8516 - val_loss: 0.0506 - val_binary_accuracy: 0.9407 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0867 - binary_accuracy: 0.8428 - val_loss: 0.0462 - val_binary_accuracy: 0.9400 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0895 - binary_accuracy: 0.8528 - val_loss: 0.0500 - val_binary_accuracy: 0.9404 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0827 - binary_accuracy: 0.8516 - val_loss: 0.0432 - val_binary_accuracy: 0.9376 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0820 - binary_accuracy: 0.8597 - val_loss: 0.0470 - val_binary_accuracy: 0.9387 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0819 - binary_accuracy: 0.8522 - val_loss: 0.0461 - val_binary_accuracy: 0.9380 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0793 - binary_accuracy: 0.8617 - val_loss: 0.0475 - val_binary_accuracy: 0.9387 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0781 - binary_accuracy: 0.8637 - val_loss: 0.0500 - val_binary_accuracy: 0.9407 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0739 - binary_accuracy: 0.8759 - val_loss: 0.0492 - val_binary_accuracy: 0.9373 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0748 - binary_accuracy: 0.8743 - val_loss: 0.0528 - val_binary_accuracy: 0.9369 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0725 - binary_accuracy: 0.8819 - val_loss: 0.0537 - val_binary_accuracy: 0.9334 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 0.0718 - binary_accuracy: 0.8747 - val_loss: 0.0528 - val_binary_accuracy: 0.9331 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0697 - binary_accuracy: 0.8847 - val_loss: 0.0544 - val_binary_accuracy: 0.9327 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0728 - binary_accuracy: 0.8743 - val_loss: 0.0537 - val_binary_accuracy: 0.9327 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0696 - binary_accuracy: 0.8827 - val_loss: 0.0540 - val_binary_accuracy: 0.9299 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0705 - binary_accuracy: 0.8781 - val_loss: 0.0550 - val_binary_accuracy: 0.9275 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0686 - binary_accuracy: 0.8839 - val_loss: 0.0554 - val_binary_accuracy: 0.9265 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0674 - binary_accuracy: 0.8877 - val_loss: 0.0566 - val_binary_accuracy: 0.9254 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0670 - binary_accuracy: 0.8905 - val_loss: 0.0572 - val_binary_accuracy: 0.9251 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0655 - binary_accuracy: 0.8877 - val_loss: 0.0584 - val_binary_accuracy: 0.9240 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0645 - binary_accuracy: 0.8958 - val_loss: 0.0607 - val_binary_accuracy: 0.9181 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0665 - binary_accuracy: 0.8873 - val_loss: 0.0592 - val_binary_accuracy: 0.9167 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0646 - binary_accuracy: 0.8889 - val_loss: 0.0610 - val_binary_accuracy: 0.9129 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0649 - binary_accuracy: 0.8887 - val_loss: 0.0628 - val_binary_accuracy: 0.9111 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0637 - binary_accuracy: 0.8939 - val_loss: 0.0642 - val_binary_accuracy: 0.9083 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0634 - binary_accuracy: 0.8891 - val_loss: 0.0633 - val_binary_accuracy: 0.9094 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0620 - binary_accuracy: 0.8966 - val_loss: 0.0645 - val_binary_accuracy: 0.9090 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0640 - binary_accuracy: 0.8893 - val_loss: 0.0706 - val_binary_accuracy: 0.9055 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0625 - binary_accuracy: 0.8935 - val_loss: 0.0683 - val_binary_accuracy: 0.9080 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0619 - binary_accuracy: 0.8927 - val_loss: 0.0729 - val_binary_accuracy: 0.9073 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.0620 - binary_accuracy: 0.8955 - val_loss: 0.0718 - val_binary_accuracy: 0.9087 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 1s 6ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      2698\n",
      "           1       0.36      0.69      0.47       171\n",
      "\n",
      "    accuracy                           0.91      2869\n",
      "   macro avg       0.67      0.81      0.71      2869\n",
      "weighted avg       0.94      0.91      0.92      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2489  209]\n",
      " [  53  118]]\n"
     ]
    }
   ],
   "source": [
    "# Modality groups definition\n",
    "trunk_indices = [0, 7, 8, 19, 20, 21]\n",
    "upper_limb_indices = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "lower_limb_indices = [1, 2, 3, 4, 5, 6]\n",
    "sEMG_indices = list(range(66, 70))\n",
    "\n",
    "# Function to prepare modality-specific datasets\n",
    "def prepare_modality_data(X, indices, is_sEMG=False):\n",
    "    if is_sEMG:\n",
    "        return X[:, :, indices]\n",
    "    else:\n",
    "        all_indices = []\n",
    "        for i in indices:\n",
    "            all_indices.extend([i, i+22, i+44])\n",
    "        return X[:, :, all_indices]\n",
    "\n",
    "# Define modalities\n",
    "modalities = {\n",
    "    \"Trunk\": trunk_indices,\n",
    "    \"Upper Limb\": upper_limb_indices,\n",
    "    \"Lower Limb\": lower_limb_indices,\n",
    "    \"sEMG\": sEMG_indices\n",
    "}\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for modality_name, indices in modalities.items():\n",
    "    is_sEMG = (modality_name == \"sEMG\")\n",
    "    X_train_modality = prepare_modality_data(X_train, indices, is_sEMG)\n",
    "    X_valid_modality = prepare_modality_data(X_valid, indices, is_sEMG)\n",
    "\n",
    "    input_shape = (X_train_modality.shape[1], X_train_modality.shape[2])\n",
    "    model = enhanced_cnn_with_attention(input_shape)  # Use cnn_normal instead of stacked_lstm\n",
    "    y_pred_modality, y_true_modality, _ = model_pipeline(model, X_train_modality, y_train, X_valid_modality, y_valid)\n",
    "\n",
    "    predictions[modality_name] = y_pred_modality\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9194841408156152\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      2698\n",
      "           1       0.38      0.54      0.44       171\n",
      "\n",
      "    accuracy                           0.92      2869\n",
      "   macro avg       0.67      0.74      0.70      2869\n",
      "weighted avg       0.93      0.92      0.93      2869\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2546  152]\n",
      " [  79   92]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "predictions_list = [predictions[modality] for modality in modalities.keys()]\n",
    "\n",
    "weighted_predictions = np.zeros(predictions_list[0].shape)\n",
    "\n",
    "# Apply the clipped and redistributed weights to the predictions\n",
    "for i, prediction in enumerate(predictions_list):\n",
    "    # print(clipped_weights[i])\n",
    "    weighted_predictions += prediction * clipped_weights[i]\n",
    "    # weighted_predictions += prediction / 4\n",
    "\n",
    "# print(weighted_predictions)\n",
    "\n",
    "\n",
    "final_predictions = np.round(weighted_predictions)\n",
    "\n",
    "# Convert y_valid to class indices if it's in one-hot encoding\n",
    "y_valid_indices = np.argmax(y_valid, axis=1)\n",
    "\n",
    "# Evaluate the combined predictions\n",
    "accuracy = accuracy_score(y_valid_indices, final_predictions)\n",
    "classification_report_result = classification_report(y_valid_indices, final_predictions)\n",
    "confusion_matrix_result = confusion_matrix(y_valid_indices, final_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report_result)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
