{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils import load_data, flatten_data\n",
    "from early_model import stacked_lstm\n",
    "from model_utils import model_pipeline, plot_history\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C56D is not selected to be used for training (downsampling)\n",
      "C93D is not selected to be used for training (downsampling)\n",
      "C382D is not selected to be used for training (downsampling)\n",
      "C382N is not selected to be used for training (downsampling)\n",
      "C544D is not selected to be used for training (downsampling)\n",
      "C709N is not selected to be used for training (downsampling)\n",
      "C788N is not selected to be used for training (downsampling)\n",
      "P113D is selected to be used for training (downsampling)\n",
      "P113N is selected to be used for training (downsampling)\n",
      "P191D is selected to be used for training (downsampling)\n",
      "P191N is selected to be used for training (downsampling)\n",
      "P299D is selected to be used for training (downsampling)\n",
      "P299N is selected to be used for training (downsampling)\n",
      "P300D is selected to be used for training (downsampling)\n",
      "P336D is selected to be used for training (downsampling)\n",
      "P492D is selected to be used for training (downsampling)\n",
      "P492N is selected to be used for training (downsampling)\n",
      "P531N is selected to be used for training (downsampling)\n",
      "P699D is selected to be used for training (downsampling)\n",
      "P699N is selected to be used for training (downsampling)\n",
      "P890N is selected to be used for training (downsampling)\n",
      "P921D is selected to be used for training (downsampling)\n",
      "P921N is selected to be used for training (downsampling)\n"
     ]
    }
   ],
   "source": [
    "train_participant_num = [\"C56D\", \"C93D\", \"C382D\", \"C382N\", \"C544D\", \"C709N\", \"C788N\", \"P113D\", \"P113N\", \"P191D\", \"P191N\", \"P299D\", \"P299N\", \"P300D\", \"P336D\", \"P492D\", \"P492N\", \"P531N\", \"P699D\", \"P699N\", \"P890N\", \"P921D\", \"P921N\"]\n",
    "valid_participant_num = [\"C67D\", \"C202D\", \"C202N\", \"C256D\", \"C256N\", \"P54D\", \"P54N\", \"P342D\", \"P342N\", \"P487D\", \"P487N\", \"P649N\"]\n",
    "\n",
    "X_train, y_train = load_data(train_participant_num, 'train', downsampling=True, angle_energy=False, augment=False)\n",
    "X_valid, y_valid = load_data(valid_participant_num, 'validation')\n",
    "\n",
    "num_classes = y_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations for Trunk: [-0.0005935154175248134]\n",
      "Correlations for Upper Limb: [-5.168494671029889e-05]\n",
      "Correlations for Lower Limb: [-0.000717485724721992]\n",
      "Correlations for sEMG signals: -0.0029697894500262632\n",
      "Correlations for All: [-0.0005935154175248134, -5.168494671029889e-05, -0.000717485724721992, -0.0029697894500262632]\n"
     ]
    }
   ],
   "source": [
    "X_train_XYZ = X_train[:, :, :66]  # XYZ坐标\n",
    "X_train_sEMG = X_train[:, :, 66:70]  # sEMG数据\n",
    "\n",
    "# 定义模态分组\n",
    "trunk_indices = [0, 7, 8, 19, 20, 21]  # 身体躯干模态索引\n",
    "upper_limb_indices = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]  # 上肢模态索引\n",
    "lower_limb_indices = [1, 2, 3, 4, 5, 6]  # 下肢模态索引\n",
    "\n",
    "# 初始化相关性列表\n",
    "correlations_trunk = []\n",
    "correlations_upper_limb = []\n",
    "correlations_lower_limb = []\n",
    "\n",
    "# 分别计算每个模态组的相关性\n",
    "for group, correlations in [(trunk_indices, correlations_trunk),\n",
    "                            (upper_limb_indices, correlations_upper_limb),\n",
    "                            (lower_limb_indices, correlations_lower_limb)]:\n",
    "    group_correlations = []\n",
    "    for i in group:\n",
    "        # 获取每个XYZ坐标的展平后的数组\n",
    "        X_flat = X_train[:, :, i].flatten()\n",
    "        Y_flat = X_train[:, :, i+22].flatten()\n",
    "        Z_flat = X_train[:, :, i+44].flatten()\n",
    "        # 为了匹配X_flat, Y_flat, Z_flat的长度，我们需要正确地重复y_train\n",
    "        y_repeated = np.repeat(y_train, X_train.shape[1])\n",
    "        # 计算相关性\n",
    "        coef_X, _ = spearmanr(X_flat, y_repeated[:len(X_flat)])\n",
    "        coef_Y, _ = spearmanr(Y_flat, y_repeated[:len(Y_flat)])\n",
    "        coef_Z, _ = spearmanr(Z_flat, y_repeated[:len(Z_flat)])\n",
    "        # 计算平均相关系数\n",
    "        avg_coef = np.mean([coef_X, coef_Y, coef_Z])\n",
    "        group_correlations.append(avg_coef)\n",
    "    # 计算并保存该模态组的平均相关性\n",
    "    avg_group_correlation = np.mean(group_correlations)\n",
    "    correlations.append(avg_group_correlation)\n",
    "\n",
    "# 对sEMG数据计算相关性\n",
    "correlations_sEMG = []\n",
    "for i in range(4):\n",
    "    sEMG_flat = X_train_sEMG[:, :, i].flatten()\n",
    "    y_repeated_sEMG = np.repeat(y_train, X_train_sEMG.shape[1])\n",
    "    coef_sEMG, _ = spearmanr(sEMG_flat, y_repeated_sEMG[:len(sEMG_flat)])\n",
    "    correlations_sEMG.append(coef_sEMG)\n",
    "\n",
    "correlation_sEMG = np.mean(correlations_sEMG)\n",
    "\n",
    "all_correlations = []\n",
    "all_correlations.append(correlations_trunk[0])\n",
    "\n",
    "all_correlations.append(correlations_upper_limb[0])\n",
    "all_correlations.append(correlations_lower_limb[0])\n",
    "all_correlations.append(correlation_sEMG)\n",
    "\n",
    "\n",
    "# 打印相关性结果\n",
    "print(\"Correlations for Trunk:\", correlations_trunk)\n",
    "print(\"Correlations for Upper Limb:\", correlations_upper_limb)\n",
    "print(\"Correlations for Lower Limb:\", correlations_lower_limb)\n",
    "print(\"Correlations for sEMG signals:\", correlation_sEMG)\n",
    "print(\"Correlations for All:\", all_correlations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21777408 0.01896436 0.26326156 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate absolute values and normalize to get initial weights\n",
    "abs_correlations = np.abs(all_correlations)\n",
    "normalized_weights = abs_correlations / np.sum(abs_correlations)\n",
    "\n",
    "# Clip weights exceeding the threshold and redistribute if necessary\n",
    "max_threshold = 0.5\n",
    "clipped_weights = np.clip(normalized_weights, None, max_threshold)\n",
    "\n",
    "# Redistribute weights if any were clipped to the threshold\n",
    "if np.any(clipped_weights == max_threshold):\n",
    "    # Calculate the total weight to be redistributed among non-clipped weights\n",
    "    total_redistribute_weight = 1 - np.sum(clipped_weights == max_threshold) * max_threshold\n",
    "    # Calculate the sum of weights that are less than the threshold (these will be redistributed)\n",
    "    sum_weights_to_redistribute = np.sum(clipped_weights[clipped_weights < max_threshold])\n",
    "    # Adjust weights that are below the threshold\n",
    "    for i, weight in enumerate(clipped_weights):\n",
    "        if weight < max_threshold:\n",
    "            clipped_weights[i] = weight / sum_weights_to_redistribute * total_redistribute_weight\n",
    "\n",
    "print(clipped_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.21777408, 0.01896436, 0.26326156, 0.5       ])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipped_weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Modality groups definition\n",
    "trunk_indices = [0, 7, 8, 19, 20, 21]\n",
    "upper_limb_indices = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "lower_limb_indices = [1, 2, 3, 4, 5, 6]\n",
    "sEMG_indices = list(range(66, 70))\n",
    "\n",
    "# Function to prepare modality-specific datasets\n",
    "def prepare_modality_data(X, indices, is_sEMG=False):\n",
    "    if is_sEMG:\n",
    "        return X[:, :, indices]\n",
    "    else:\n",
    "        all_indices = []\n",
    "        for i in indices:\n",
    "            all_indices.extend([i, i+22, i+44])\n",
    "        return X[:, :, all_indices]\n",
    "\n",
    "# Define modalities\n",
    "modalities = {\n",
    "    \"Trunk\": trunk_indices,\n",
    "    \"Upper Limb\": upper_limb_indices,\n",
    "    \"Lower Limb\": lower_limb_indices,\n",
    "    \"sEMG\": sEMG_indices\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 6s 436ms/step - loss: 0.1960 - binary_accuracy: 0.5186 - val_loss: 0.1198 - val_binary_accuracy: 0.9306 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 4s 352ms/step - loss: 0.1570 - binary_accuracy: 0.7043 - val_loss: 0.0979 - val_binary_accuracy: 0.9366 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 4s 388ms/step - loss: 0.1457 - binary_accuracy: 0.7474 - val_loss: 0.0954 - val_binary_accuracy: 0.9400 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 4s 371ms/step - loss: 0.1419 - binary_accuracy: 0.7586 - val_loss: 0.0916 - val_binary_accuracy: 0.9411 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 5s 419ms/step - loss: 0.1383 - binary_accuracy: 0.7702 - val_loss: 0.0908 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 4s 405ms/step - loss: 0.1358 - binary_accuracy: 0.7719 - val_loss: 0.0938 - val_binary_accuracy: 0.9394 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 4s 391ms/step - loss: 0.1329 - binary_accuracy: 0.7763 - val_loss: 0.0874 - val_binary_accuracy: 0.9390 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 4s 401ms/step - loss: 0.1343 - binary_accuracy: 0.7803 - val_loss: 0.0816 - val_binary_accuracy: 0.9355 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 4s 390ms/step - loss: 0.1346 - binary_accuracy: 0.7767 - val_loss: 0.0865 - val_binary_accuracy: 0.9355 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 4s 409ms/step - loss: 0.1291 - binary_accuracy: 0.7797 - val_loss: 0.0897 - val_binary_accuracy: 0.9373 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 5s 416ms/step - loss: 0.1290 - binary_accuracy: 0.7863 - val_loss: 0.0863 - val_binary_accuracy: 0.9390 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 5s 420ms/step - loss: 0.1265 - binary_accuracy: 0.7871 - val_loss: 0.0833 - val_binary_accuracy: 0.9320 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 4s 402ms/step - loss: 0.1266 - binary_accuracy: 0.7839 - val_loss: 0.0806 - val_binary_accuracy: 0.9306 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 4s 377ms/step - loss: 0.1252 - binary_accuracy: 0.7843 - val_loss: 0.0863 - val_binary_accuracy: 0.9306 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 4s 411ms/step - loss: 0.1255 - binary_accuracy: 0.7851 - val_loss: 0.0778 - val_binary_accuracy: 0.9303 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 4s 402ms/step - loss: 0.1250 - binary_accuracy: 0.7853 - val_loss: 0.0870 - val_binary_accuracy: 0.9268 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 5s 434ms/step - loss: 0.1240 - binary_accuracy: 0.7851 - val_loss: 0.0801 - val_binary_accuracy: 0.9268 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 5s 411ms/step - loss: 0.1222 - binary_accuracy: 0.7885 - val_loss: 0.0904 - val_binary_accuracy: 0.9265 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 5s 414ms/step - loss: 0.1230 - binary_accuracy: 0.7827 - val_loss: 0.0813 - val_binary_accuracy: 0.9244 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 4s 403ms/step - loss: 0.1215 - binary_accuracy: 0.7831 - val_loss: 0.0909 - val_binary_accuracy: 0.9254 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 5s 428ms/step - loss: 0.1217 - binary_accuracy: 0.7859 - val_loss: 0.0811 - val_binary_accuracy: 0.9292 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 5s 436ms/step - loss: 0.1186 - binary_accuracy: 0.7899 - val_loss: 0.0910 - val_binary_accuracy: 0.9265 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 4s 384ms/step - loss: 0.1181 - binary_accuracy: 0.7955 - val_loss: 0.0858 - val_binary_accuracy: 0.9244 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 4s 392ms/step - loss: 0.1187 - binary_accuracy: 0.7891 - val_loss: 0.0900 - val_binary_accuracy: 0.9237 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 5s 414ms/step - loss: 0.1175 - binary_accuracy: 0.7947 - val_loss: 0.0858 - val_binary_accuracy: 0.9216 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 4s 389ms/step - loss: 0.1167 - binary_accuracy: 0.7961 - val_loss: 0.0902 - val_binary_accuracy: 0.9226 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 5s 432ms/step - loss: 0.1172 - binary_accuracy: 0.7919 - val_loss: 0.0885 - val_binary_accuracy: 0.9216 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 4s 377ms/step - loss: 0.1167 - binary_accuracy: 0.7939 - val_loss: 0.0932 - val_binary_accuracy: 0.9230 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 5s 428ms/step - loss: 0.1151 - binary_accuracy: 0.7917 - val_loss: 0.0883 - val_binary_accuracy: 0.9212 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 4s 403ms/step - loss: 0.1139 - binary_accuracy: 0.7947 - val_loss: 0.0969 - val_binary_accuracy: 0.9216 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 4s 394ms/step - loss: 0.1153 - binary_accuracy: 0.7987 - val_loss: 0.0897 - val_binary_accuracy: 0.9202 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 4s 407ms/step - loss: 0.1147 - binary_accuracy: 0.7923 - val_loss: 0.0921 - val_binary_accuracy: 0.9209 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 4s 400ms/step - loss: 0.1152 - binary_accuracy: 0.7933 - val_loss: 0.0936 - val_binary_accuracy: 0.9191 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 5s 414ms/step - loss: 0.1127 - binary_accuracy: 0.7937 - val_loss: 0.0920 - val_binary_accuracy: 0.9115 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 5s 424ms/step - loss: 0.1135 - binary_accuracy: 0.7921 - val_loss: 0.0946 - val_binary_accuracy: 0.8972 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 5s 426ms/step - loss: 0.1126 - binary_accuracy: 0.7937 - val_loss: 0.0923 - val_binary_accuracy: 0.8968 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 4s 405ms/step - loss: 0.1126 - binary_accuracy: 0.7925 - val_loss: 0.0959 - val_binary_accuracy: 0.9010 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 5s 420ms/step - loss: 0.1144 - binary_accuracy: 0.7905 - val_loss: 0.0949 - val_binary_accuracy: 0.8930 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 5s 419ms/step - loss: 0.1120 - binary_accuracy: 0.8009 - val_loss: 0.0960 - val_binary_accuracy: 0.8899 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 5s 451ms/step - loss: 0.1119 - binary_accuracy: 0.7957 - val_loss: 0.0948 - val_binary_accuracy: 0.8871 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 5s 419ms/step - loss: 0.1128 - binary_accuracy: 0.7863 - val_loss: 0.0973 - val_binary_accuracy: 0.8846 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 4s 380ms/step - loss: 0.1114 - binary_accuracy: 0.8017 - val_loss: 0.0993 - val_binary_accuracy: 0.8602 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 5s 431ms/step - loss: 0.1109 - binary_accuracy: 0.7979 - val_loss: 0.0961 - val_binary_accuracy: 0.8797 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 5s 424ms/step - loss: 0.1110 - binary_accuracy: 0.7957 - val_loss: 0.0991 - val_binary_accuracy: 0.8707 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 4s 393ms/step - loss: 0.1116 - binary_accuracy: 0.7987 - val_loss: 0.0984 - val_binary_accuracy: 0.8731 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 4s 413ms/step - loss: 0.1107 - binary_accuracy: 0.7991 - val_loss: 0.0984 - val_binary_accuracy: 0.8742 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 4s 408ms/step - loss: 0.1102 - binary_accuracy: 0.7963 - val_loss: 0.1004 - val_binary_accuracy: 0.8721 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 4s 393ms/step - loss: 0.1096 - binary_accuracy: 0.8025 - val_loss: 0.1003 - val_binary_accuracy: 0.8707 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 5s 412ms/step - loss: 0.1107 - binary_accuracy: 0.7893 - val_loss: 0.1005 - val_binary_accuracy: 0.8707 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 5s 471ms/step - loss: 0.1107 - binary_accuracy: 0.7977 - val_loss: 0.1019 - val_binary_accuracy: 0.8651 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 1s 9ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      2698\n",
      "           1       0.06      0.09      0.08       171\n",
      "\n",
      "    accuracy                           0.87      2869\n",
      "   macro avg       0.50      0.50      0.50      2869\n",
      "weighted avg       0.89      0.87      0.88      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2466  232]\n",
      " [ 155   16]]\n",
      "here\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 6s 484ms/step - loss: 0.1600 - binary_accuracy: 0.7336 - val_loss: 0.0911 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 6s 513ms/step - loss: 0.1473 - binary_accuracy: 0.7680 - val_loss: 0.0939 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 5s 498ms/step - loss: 0.1415 - binary_accuracy: 0.7674 - val_loss: 0.0995 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 6s 524ms/step - loss: 0.1419 - binary_accuracy: 0.7650 - val_loss: 0.0996 - val_binary_accuracy: 0.9359 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 5s 499ms/step - loss: 0.1381 - binary_accuracy: 0.7666 - val_loss: 0.0955 - val_binary_accuracy: 0.9380 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 5s 493ms/step - loss: 0.1352 - binary_accuracy: 0.7711 - val_loss: 0.0944 - val_binary_accuracy: 0.9387 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 5s 493ms/step - loss: 0.1318 - binary_accuracy: 0.7799 - val_loss: 0.0894 - val_binary_accuracy: 0.9383 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 5s 480ms/step - loss: 0.1309 - binary_accuracy: 0.7821 - val_loss: 0.0868 - val_binary_accuracy: 0.9383 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 5s 484ms/step - loss: 0.1331 - binary_accuracy: 0.7783 - val_loss: 0.0907 - val_binary_accuracy: 0.9394 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 5s 495ms/step - loss: 0.1324 - binary_accuracy: 0.7793 - val_loss: 0.0875 - val_binary_accuracy: 0.9394 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 5s 465ms/step - loss: 0.1301 - binary_accuracy: 0.7821 - val_loss: 0.0812 - val_binary_accuracy: 0.9407 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 5s 480ms/step - loss: 0.1279 - binary_accuracy: 0.7835 - val_loss: 0.0875 - val_binary_accuracy: 0.9411 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 5s 501ms/step - loss: 0.1292 - binary_accuracy: 0.7791 - val_loss: 0.0861 - val_binary_accuracy: 0.9404 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 6s 533ms/step - loss: 0.1278 - binary_accuracy: 0.7867 - val_loss: 0.0848 - val_binary_accuracy: 0.9397 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 5s 482ms/step - loss: 0.1251 - binary_accuracy: 0.7817 - val_loss: 0.0874 - val_binary_accuracy: 0.9394 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 5s 485ms/step - loss: 0.1251 - binary_accuracy: 0.7853 - val_loss: 0.0825 - val_binary_accuracy: 0.9394 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.1235 - binary_accuracy: 0.7855 - val_loss: 0.0854 - val_binary_accuracy: 0.9387 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 5s 489ms/step - loss: 0.1251 - binary_accuracy: 0.7825 - val_loss: 0.0846 - val_binary_accuracy: 0.9394 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 5s 459ms/step - loss: 0.1245 - binary_accuracy: 0.7831 - val_loss: 0.0859 - val_binary_accuracy: 0.9380 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 5s 503ms/step - loss: 0.1241 - binary_accuracy: 0.7847 - val_loss: 0.0866 - val_binary_accuracy: 0.9383 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 6s 505ms/step - loss: 0.1219 - binary_accuracy: 0.7877 - val_loss: 0.0822 - val_binary_accuracy: 0.9376 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 0.1222 - binary_accuracy: 0.7861 - val_loss: 0.0830 - val_binary_accuracy: 0.9373 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 5s 503ms/step - loss: 0.1217 - binary_accuracy: 0.7921 - val_loss: 0.0824 - val_binary_accuracy: 0.9362 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 5s 490ms/step - loss: 0.1227 - binary_accuracy: 0.7911 - val_loss: 0.0832 - val_binary_accuracy: 0.9369 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 5s 494ms/step - loss: 0.1213 - binary_accuracy: 0.7869 - val_loss: 0.0852 - val_binary_accuracy: 0.9331 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 5s 489ms/step - loss: 0.1207 - binary_accuracy: 0.7833 - val_loss: 0.0860 - val_binary_accuracy: 0.9303 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 5s 492ms/step - loss: 0.1207 - binary_accuracy: 0.7919 - val_loss: 0.0837 - val_binary_accuracy: 0.9292 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 6s 512ms/step - loss: 0.1184 - binary_accuracy: 0.7865 - val_loss: 0.0859 - val_binary_accuracy: 0.9268 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 6s 530ms/step - loss: 0.1200 - binary_accuracy: 0.7885 - val_loss: 0.0865 - val_binary_accuracy: 0.9209 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 6s 516ms/step - loss: 0.1199 - binary_accuracy: 0.7873 - val_loss: 0.0858 - val_binary_accuracy: 0.9299 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 5s 503ms/step - loss: 0.1191 - binary_accuracy: 0.7863 - val_loss: 0.0864 - val_binary_accuracy: 0.9237 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 5s 467ms/step - loss: 0.1184 - binary_accuracy: 0.7901 - val_loss: 0.0848 - val_binary_accuracy: 0.9247 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 5s 471ms/step - loss: 0.1194 - binary_accuracy: 0.7895 - val_loss: 0.0860 - val_binary_accuracy: 0.9212 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 6s 531ms/step - loss: 0.1174 - binary_accuracy: 0.7837 - val_loss: 0.0873 - val_binary_accuracy: 0.9251 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 5s 472ms/step - loss: 0.1169 - binary_accuracy: 0.7897 - val_loss: 0.0873 - val_binary_accuracy: 0.9230 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 6s 513ms/step - loss: 0.1155 - binary_accuracy: 0.7915 - val_loss: 0.0874 - val_binary_accuracy: 0.9226 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 6s 510ms/step - loss: 0.1176 - binary_accuracy: 0.7901 - val_loss: 0.0871 - val_binary_accuracy: 0.9223 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 6s 500ms/step - loss: 0.1158 - binary_accuracy: 0.7927 - val_loss: 0.0874 - val_binary_accuracy: 0.9188 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 5s 467ms/step - loss: 0.1141 - binary_accuracy: 0.7897 - val_loss: 0.0868 - val_binary_accuracy: 0.9191 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 5s 492ms/step - loss: 0.1148 - binary_accuracy: 0.7867 - val_loss: 0.0874 - val_binary_accuracy: 0.9216 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 5s 483ms/step - loss: 0.1165 - binary_accuracy: 0.7893 - val_loss: 0.0879 - val_binary_accuracy: 0.9205 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 6s 538ms/step - loss: 0.1161 - binary_accuracy: 0.7881 - val_loss: 0.0897 - val_binary_accuracy: 0.9198 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 6s 516ms/step - loss: 0.1144 - binary_accuracy: 0.7879 - val_loss: 0.0900 - val_binary_accuracy: 0.9167 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 5s 487ms/step - loss: 0.1162 - binary_accuracy: 0.7899 - val_loss: 0.0895 - val_binary_accuracy: 0.9101 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 5s 499ms/step - loss: 0.1139 - binary_accuracy: 0.7929 - val_loss: 0.0906 - val_binary_accuracy: 0.9087 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 5s 459ms/step - loss: 0.1142 - binary_accuracy: 0.7911 - val_loss: 0.0906 - val_binary_accuracy: 0.9097 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 5s 470ms/step - loss: 0.1133 - binary_accuracy: 0.7917 - val_loss: 0.0906 - val_binary_accuracy: 0.9080 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 5s 470ms/step - loss: 0.1135 - binary_accuracy: 0.7867 - val_loss: 0.0929 - val_binary_accuracy: 0.9069 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 5s 492ms/step - loss: 0.1155 - binary_accuracy: 0.7859 - val_loss: 0.0937 - val_binary_accuracy: 0.9062 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 6s 531ms/step - loss: 0.1143 - binary_accuracy: 0.7883 - val_loss: 0.0940 - val_binary_accuracy: 0.9052 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 1s 10ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      2698\n",
      "           1       0.07      0.05      0.06       171\n",
      "\n",
      "    accuracy                           0.91      2869\n",
      "   macro avg       0.50      0.50      0.50      2869\n",
      "weighted avg       0.89      0.91      0.90      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2589  109]\n",
      " [ 163    8]]\n",
      "here\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 494ms/step - loss: 0.1732 - binary_accuracy: 0.6686 - val_loss: 0.1041 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 5s 433ms/step - loss: 0.1502 - binary_accuracy: 0.7422 - val_loss: 0.1021 - val_binary_accuracy: 0.9414 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 5s 414ms/step - loss: 0.1426 - binary_accuracy: 0.7564 - val_loss: 0.1035 - val_binary_accuracy: 0.9400 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 5s 444ms/step - loss: 0.1398 - binary_accuracy: 0.7662 - val_loss: 0.1025 - val_binary_accuracy: 0.9383 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 5s 452ms/step - loss: 0.1375 - binary_accuracy: 0.7676 - val_loss: 0.1006 - val_binary_accuracy: 0.9376 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 5s 472ms/step - loss: 0.1364 - binary_accuracy: 0.7727 - val_loss: 0.1012 - val_binary_accuracy: 0.9376 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 5s 451ms/step - loss: 0.1339 - binary_accuracy: 0.7706 - val_loss: 0.1027 - val_binary_accuracy: 0.9376 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 5s 445ms/step - loss: 0.1350 - binary_accuracy: 0.7753 - val_loss: 0.1007 - val_binary_accuracy: 0.9383 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 5s 417ms/step - loss: 0.1333 - binary_accuracy: 0.7795 - val_loss: 0.0966 - val_binary_accuracy: 0.9380 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 5s 424ms/step - loss: 0.1330 - binary_accuracy: 0.7767 - val_loss: 0.0916 - val_binary_accuracy: 0.9373 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 5s 438ms/step - loss: 0.1299 - binary_accuracy: 0.7799 - val_loss: 0.0944 - val_binary_accuracy: 0.9366 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 5s 420ms/step - loss: 0.1290 - binary_accuracy: 0.7763 - val_loss: 0.0942 - val_binary_accuracy: 0.9355 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 5s 461ms/step - loss: 0.1294 - binary_accuracy: 0.7795 - val_loss: 0.0912 - val_binary_accuracy: 0.9362 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 5s 468ms/step - loss: 0.1251 - binary_accuracy: 0.7765 - val_loss: 0.0884 - val_binary_accuracy: 0.9338 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 5s 467ms/step - loss: 0.1249 - binary_accuracy: 0.7749 - val_loss: 0.0929 - val_binary_accuracy: 0.9383 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 5s 469ms/step - loss: 0.1254 - binary_accuracy: 0.7765 - val_loss: 0.0896 - val_binary_accuracy: 0.9394 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 4s 387ms/step - loss: 0.1261 - binary_accuracy: 0.7835 - val_loss: 0.0908 - val_binary_accuracy: 0.9394 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 5s 490ms/step - loss: 0.1240 - binary_accuracy: 0.7813 - val_loss: 0.0898 - val_binary_accuracy: 0.9400 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 5s 446ms/step - loss: 0.1237 - binary_accuracy: 0.7835 - val_loss: 0.0891 - val_binary_accuracy: 0.9380 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 5s 440ms/step - loss: 0.1232 - binary_accuracy: 0.7841 - val_loss: 0.0917 - val_binary_accuracy: 0.9383 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 5s 469ms/step - loss: 0.1226 - binary_accuracy: 0.7831 - val_loss: 0.0960 - val_binary_accuracy: 0.9390 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 5s 450ms/step - loss: 0.1216 - binary_accuracy: 0.7791 - val_loss: 0.0937 - val_binary_accuracy: 0.9390 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 5s 444ms/step - loss: 0.1217 - binary_accuracy: 0.7851 - val_loss: 0.0884 - val_binary_accuracy: 0.9390 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 5s 433ms/step - loss: 0.1229 - binary_accuracy: 0.7863 - val_loss: 0.0937 - val_binary_accuracy: 0.9369 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 4s 396ms/step - loss: 0.1215 - binary_accuracy: 0.7851 - val_loss: 0.0912 - val_binary_accuracy: 0.9373 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 5s 426ms/step - loss: 0.1209 - binary_accuracy: 0.7833 - val_loss: 0.0883 - val_binary_accuracy: 0.9380 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 5s 449ms/step - loss: 0.1197 - binary_accuracy: 0.7855 - val_loss: 0.0921 - val_binary_accuracy: 0.9383 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 5s 480ms/step - loss: 0.1202 - binary_accuracy: 0.7851 - val_loss: 0.0927 - val_binary_accuracy: 0.9369 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 5s 447ms/step - loss: 0.1185 - binary_accuracy: 0.7857 - val_loss: 0.0944 - val_binary_accuracy: 0.9366 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 5s 439ms/step - loss: 0.1176 - binary_accuracy: 0.7949 - val_loss: 0.0942 - val_binary_accuracy: 0.9355 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 5s 450ms/step - loss: 0.1176 - binary_accuracy: 0.7903 - val_loss: 0.0949 - val_binary_accuracy: 0.9355 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 5s 464ms/step - loss: 0.1181 - binary_accuracy: 0.7825 - val_loss: 0.0939 - val_binary_accuracy: 0.9348 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 5s 450ms/step - loss: 0.1175 - binary_accuracy: 0.7861 - val_loss: 0.0936 - val_binary_accuracy: 0.9310 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 5s 449ms/step - loss: 0.1170 - binary_accuracy: 0.7871 - val_loss: 0.0940 - val_binary_accuracy: 0.9292 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 5s 410ms/step - loss: 0.1170 - binary_accuracy: 0.7835 - val_loss: 0.0928 - val_binary_accuracy: 0.9310 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 5s 456ms/step - loss: 0.1175 - binary_accuracy: 0.7963 - val_loss: 0.0921 - val_binary_accuracy: 0.9324 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 5s 486ms/step - loss: 0.1169 - binary_accuracy: 0.7881 - val_loss: 0.0963 - val_binary_accuracy: 0.9313 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 5s 428ms/step - loss: 0.1155 - binary_accuracy: 0.7887 - val_loss: 0.0954 - val_binary_accuracy: 0.9306 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 5s 471ms/step - loss: 0.1147 - binary_accuracy: 0.7919 - val_loss: 0.0958 - val_binary_accuracy: 0.9289 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 5s 415ms/step - loss: 0.1157 - binary_accuracy: 0.7953 - val_loss: 0.0952 - val_binary_accuracy: 0.9289 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 5s 459ms/step - loss: 0.1147 - binary_accuracy: 0.7915 - val_loss: 0.0889 - val_binary_accuracy: 0.9303 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 5s 439ms/step - loss: 0.1137 - binary_accuracy: 0.7933 - val_loss: 0.0890 - val_binary_accuracy: 0.9289 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 5s 433ms/step - loss: 0.1136 - binary_accuracy: 0.7871 - val_loss: 0.0879 - val_binary_accuracy: 0.9303 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 5s 452ms/step - loss: 0.1141 - binary_accuracy: 0.7889 - val_loss: 0.0889 - val_binary_accuracy: 0.9296 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 0.1131 - binary_accuracy: 0.7893 - val_loss: 0.0863 - val_binary_accuracy: 0.9289 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 5s 453ms/step - loss: 0.1129 - binary_accuracy: 0.7903 - val_loss: 0.0868 - val_binary_accuracy: 0.9285 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 5s 462ms/step - loss: 0.1121 - binary_accuracy: 0.7925 - val_loss: 0.0856 - val_binary_accuracy: 0.9282 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 5s 492ms/step - loss: 0.1117 - binary_accuracy: 0.7911 - val_loss: 0.0864 - val_binary_accuracy: 0.9240 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 5s 454ms/step - loss: 0.1117 - binary_accuracy: 0.7891 - val_loss: 0.0865 - val_binary_accuracy: 0.9240 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 6s 532ms/step - loss: 0.1104 - binary_accuracy: 0.7923 - val_loss: 0.0858 - val_binary_accuracy: 0.9251 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 1s 10ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2698\n",
      "           1       0.16      0.06      0.09       171\n",
      "\n",
      "    accuracy                           0.93      2869\n",
      "   macro avg       0.55      0.52      0.52      2869\n",
      "weighted avg       0.90      0.93      0.91      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2644   54]\n",
      " [ 161   10]]\n",
      "here\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 539ms/step - loss: 0.1683 - binary_accuracy: 0.7266 - val_loss: 0.1502 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 4s 402ms/step - loss: 0.1532 - binary_accuracy: 0.7803 - val_loss: 0.1072 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 5s 427ms/step - loss: 0.1447 - binary_accuracy: 0.7823 - val_loss: 0.0933 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 4s 388ms/step - loss: 0.1396 - binary_accuracy: 0.7887 - val_loss: 0.1060 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 5s 424ms/step - loss: 0.1373 - binary_accuracy: 0.7899 - val_loss: 0.0989 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 5s 434ms/step - loss: 0.1361 - binary_accuracy: 0.7901 - val_loss: 0.0903 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 5s 423ms/step - loss: 0.1343 - binary_accuracy: 0.7899 - val_loss: 0.0898 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 4s 369ms/step - loss: 0.1336 - binary_accuracy: 0.7899 - val_loss: 0.0901 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 4s 387ms/step - loss: 0.1333 - binary_accuracy: 0.7899 - val_loss: 0.0900 - val_binary_accuracy: 0.9404 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 4s 364ms/step - loss: 0.1320 - binary_accuracy: 0.7901 - val_loss: 0.0844 - val_binary_accuracy: 0.9390 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 4s 360ms/step - loss: 0.1300 - binary_accuracy: 0.7963 - val_loss: 0.0800 - val_binary_accuracy: 0.9362 - lr: 9.5000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 4s 390ms/step - loss: 0.1296 - binary_accuracy: 0.7939 - val_loss: 0.0767 - val_binary_accuracy: 0.9380 - lr: 9.0250e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 5s 416ms/step - loss: 0.1287 - binary_accuracy: 0.7973 - val_loss: 0.0767 - val_binary_accuracy: 0.9380 - lr: 8.5737e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.1296 - binary_accuracy: 0.7961 - val_loss: 0.0816 - val_binary_accuracy: 0.9380 - lr: 8.1451e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 4s 387ms/step - loss: 0.1297 - binary_accuracy: 0.7991 - val_loss: 0.0790 - val_binary_accuracy: 0.9359 - lr: 7.7378e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 5s 411ms/step - loss: 0.1284 - binary_accuracy: 0.7945 - val_loss: 0.0747 - val_binary_accuracy: 0.9373 - lr: 7.3509e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 4s 369ms/step - loss: 0.1272 - binary_accuracy: 0.7983 - val_loss: 0.0792 - val_binary_accuracy: 0.9338 - lr: 6.9834e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 4s 385ms/step - loss: 0.1285 - binary_accuracy: 0.7985 - val_loss: 0.0778 - val_binary_accuracy: 0.9352 - lr: 6.6342e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 5s 433ms/step - loss: 0.1290 - binary_accuracy: 0.8009 - val_loss: 0.0759 - val_binary_accuracy: 0.9359 - lr: 6.3025e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 4s 369ms/step - loss: 0.1281 - binary_accuracy: 0.8001 - val_loss: 0.0744 - val_binary_accuracy: 0.9373 - lr: 5.9874e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 5s 428ms/step - loss: 0.1284 - binary_accuracy: 0.7971 - val_loss: 0.0757 - val_binary_accuracy: 0.9376 - lr: 5.6880e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 4s 413ms/step - loss: 0.1269 - binary_accuracy: 0.7981 - val_loss: 0.0756 - val_binary_accuracy: 0.9404 - lr: 5.4036e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 4s 371ms/step - loss: 0.1271 - binary_accuracy: 0.7989 - val_loss: 0.0750 - val_binary_accuracy: 0.9383 - lr: 5.1334e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 4s 382ms/step - loss: 0.1284 - binary_accuracy: 0.8009 - val_loss: 0.0711 - val_binary_accuracy: 0.9397 - lr: 4.8767e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 4s 378ms/step - loss: 0.1267 - binary_accuracy: 0.8027 - val_loss: 0.0700 - val_binary_accuracy: 0.9369 - lr: 4.6329e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 4s 387ms/step - loss: 0.1263 - binary_accuracy: 0.7987 - val_loss: 0.0698 - val_binary_accuracy: 0.9331 - lr: 4.4013e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 4s 361ms/step - loss: 0.1268 - binary_accuracy: 0.7987 - val_loss: 0.0716 - val_binary_accuracy: 0.9313 - lr: 4.1812e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 4s 382ms/step - loss: 0.1282 - binary_accuracy: 0.7923 - val_loss: 0.0696 - val_binary_accuracy: 0.9292 - lr: 3.9721e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 0.1250 - binary_accuracy: 0.7993 - val_loss: 0.0663 - val_binary_accuracy: 0.9345 - lr: 3.7735e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 4s 392ms/step - loss: 0.1251 - binary_accuracy: 0.8017 - val_loss: 0.0669 - val_binary_accuracy: 0.9285 - lr: 3.5849e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 4s 361ms/step - loss: 0.1261 - binary_accuracy: 0.8015 - val_loss: 0.0713 - val_binary_accuracy: 0.9059 - lr: 3.4056e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 4s 374ms/step - loss: 0.1256 - binary_accuracy: 0.7957 - val_loss: 0.0705 - val_binary_accuracy: 0.9129 - lr: 3.2353e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 4s 353ms/step - loss: 0.1269 - binary_accuracy: 0.7973 - val_loss: 0.0708 - val_binary_accuracy: 0.9150 - lr: 3.0736e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 4s 366ms/step - loss: 0.1239 - binary_accuracy: 0.8043 - val_loss: 0.0736 - val_binary_accuracy: 0.8986 - lr: 2.9199e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 0.1243 - binary_accuracy: 0.8009 - val_loss: 0.0726 - val_binary_accuracy: 0.9052 - lr: 2.7739e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 4s 383ms/step - loss: 0.1231 - binary_accuracy: 0.8015 - val_loss: 0.0757 - val_binary_accuracy: 0.8787 - lr: 2.6352e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 4s 367ms/step - loss: 0.1242 - binary_accuracy: 0.8015 - val_loss: 0.0731 - val_binary_accuracy: 0.8986 - lr: 2.5034e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 4s 375ms/step - loss: 0.1237 - binary_accuracy: 0.8075 - val_loss: 0.0762 - val_binary_accuracy: 0.8836 - lr: 2.3783e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 4s 353ms/step - loss: 0.1222 - binary_accuracy: 0.8081 - val_loss: 0.0758 - val_binary_accuracy: 0.8857 - lr: 2.2594e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 4s 379ms/step - loss: 0.1234 - binary_accuracy: 0.8089 - val_loss: 0.0765 - val_binary_accuracy: 0.8864 - lr: 2.1464e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 4s 353ms/step - loss: 0.1231 - binary_accuracy: 0.8081 - val_loss: 0.0776 - val_binary_accuracy: 0.8787 - lr: 2.0391e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 4s 384ms/step - loss: 0.1232 - binary_accuracy: 0.8099 - val_loss: 0.0785 - val_binary_accuracy: 0.8770 - lr: 1.9371e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 4s 347ms/step - loss: 0.1217 - binary_accuracy: 0.8091 - val_loss: 0.0788 - val_binary_accuracy: 0.8763 - lr: 1.8403e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 4s 367ms/step - loss: 0.1223 - binary_accuracy: 0.8144 - val_loss: 0.0798 - val_binary_accuracy: 0.8742 - lr: 1.7482e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 4s 345ms/step - loss: 0.1223 - binary_accuracy: 0.8121 - val_loss: 0.0798 - val_binary_accuracy: 0.8759 - lr: 1.6608e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 4s 370ms/step - loss: 0.1206 - binary_accuracy: 0.8115 - val_loss: 0.0788 - val_binary_accuracy: 0.8787 - lr: 1.5778e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 4s 365ms/step - loss: 0.1232 - binary_accuracy: 0.8119 - val_loss: 0.0795 - val_binary_accuracy: 0.8773 - lr: 1.4989e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 4s 367ms/step - loss: 0.1229 - binary_accuracy: 0.8126 - val_loss: 0.0802 - val_binary_accuracy: 0.8759 - lr: 1.4240e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 4s 375ms/step - loss: 0.1222 - binary_accuracy: 0.8134 - val_loss: 0.0803 - val_binary_accuracy: 0.8794 - lr: 1.3528e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 5s 428ms/step - loss: 0.1229 - binary_accuracy: 0.8136 - val_loss: 0.0812 - val_binary_accuracy: 0.8770 - lr: 1.2851e-04\n",
      "90/90 [==============================] - 1s 10ms/step\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      2698\n",
      "           1       0.28      0.68      0.40       171\n",
      "\n",
      "    accuracy                           0.88      2869\n",
      "   macro avg       0.63      0.79      0.67      2869\n",
      "weighted avg       0.94      0.88      0.90      2869\n",
      "\n",
      "Confusion matrix:\n",
      "[[2399  299]\n",
      " [  54  117]]\n",
      "here\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "\n",
    "for modality_name, indices in modalities.items():\n",
    "    is_sEMG = (modality_name == \"sEMG\")\n",
    "    X_train_modality = prepare_modality_data(X_train, indices, is_sEMG)\n",
    "    X_valid_modality = prepare_modality_data(X_valid, indices, is_sEMG)\n",
    "\n",
    "    input_shape = (X_train_modality.shape[1], X_train_modality.shape[2])\n",
    "    model = stacked_lstm(input_shape, num_classes)\n",
    "    # model = stacked_lstm(input_shape, 1)\n",
    "    y_pred_modality, _, _ = model_pipeline(model, X_train_modality, y_train, X_valid_modality, y_valid)\n",
    "    print(\"here\")\n",
    "    print(y_pred_modality)\n",
    "\n",
    "    predictions[modality_name] = y_pred_modality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def new_ensemble_predictions(prediction1, prediction2, prediction3, prediction4, strategy='average', weights=None, rule=None):\n",
    "    \"\"\"\n",
    "    Ensembles two sets of predictions using different strategies.\n",
    "    Parameters:\n",
    "    prediction1 (np.ndarray): The first set of predictions.\n",
    "    prediction2 (np.ndarray): The second set of predictions.\n",
    "    strategy (str): The ensembling strategy to use. Options are 'average', 'product', 'max', or 'rule'.\n",
    "    weights (list): A list of weights to use for each set of predictions. If not given, defaults to equal weights.\n",
    "    rule (function): A callable rule function to use for rule-based ensembling.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The ensembled predictions.\n",
    "    \"\"\"\n",
    "    prediction1, prediction2 = np.array(prediction1), np.array(prediction2)\n",
    "    if not weights:\n",
    "        # If no weights are given, assume equal weights for both predictions\n",
    "        weights = [0.25, 0.25, 0.25, 0.25]\n",
    "    if prediction1.shape != prediction2.shape or len(weights) != 2:\n",
    "        raise ValueError(\"Both predictions must have the same shape, and weights must have a length of 2.\")\n",
    "    if strategy == 'average':\n",
    "        ensemble = prediction1 * weights[0] + prediction2 * weights[1] + prediction3 * weights[2] + prediction4 * weights[3]\n",
    "    # elif strategy == 'product':\n",
    "    #     ensemble = prediction1 * prediction2 * prediction3 * prediction4\n",
    "    # elif strategy == 'max':\n",
    "    #     ensemble = np.maximum(prediction1, prediction2, prediction3, prediction4)\n",
    "    # elif strategy == 'rule':\n",
    "    #     if not rule or not callable(rule):\n",
    "    #         raise ValueError(\"A callable rule function is required for rule-based ensembling.\")\n",
    "    #     ensemble = np.array([rule(pred1, pred2) for pred1, pred2 in zip(prediction1, prediction2)])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid ensembling strategy. Options are 'average', 'product', 'max', or 'rule'.\")\n",
    "    ensemble = np.argmax(ensemble, axis=1)\n",
    "    return ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9351690484489369\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2698\n",
      "           1       0.36      0.12      0.18       171\n",
      "\n",
      "    accuracy                           0.94      2869\n",
      "   macro avg       0.65      0.55      0.57      2869\n",
      "weighted avg       0.91      0.94      0.92      2869\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2663   35]\n",
      " [ 151   20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "predictions_list = [predictions[modality] for modality in modalities.keys()]\n",
    "\n",
    "weighted_predictions = np.zeros(predictions_list[0].shape)\n",
    "\n",
    "# Apply the clipped and redistributed weights to the predictions\n",
    "for i, prediction in enumerate(predictions_list):\n",
    "    # print(clipped_weights[i])\n",
    "    weighted_predictions += prediction * clipped_weights[i]\n",
    "    # weighted_predictions += prediction / 4\n",
    "\n",
    "# print(weighted_predictions)\n",
    "\n",
    "\n",
    "final_predictions = np.round(weighted_predictions)\n",
    "\n",
    "# Convert y_valid to class indices if it's in one-hot encoding\n",
    "y_valid_indices = np.argmax(y_valid, axis=1)\n",
    "\n",
    "# Evaluate the combined predictions\n",
    "accuracy = accuracy_score(y_valid_indices, final_predictions)\n",
    "classification_report_result = classification_report(y_valid_indices, final_predictions)\n",
    "confusion_matrix_result = confusion_matrix(y_valid_indices, final_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report_result)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
